{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa166c8f436bbb8",
   "metadata": {},
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **LÃ©o FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc574ebf57602201",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 : Data collection"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5caf94fc63fdaf4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from Jira import jira_download\n",
    "from pandas import Index\n",
    "from numpy import ndarray\n",
    "\n",
    "from projet.leo.metrics import added_lines, deleted_lines, commit_count, dev_count"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af4622a84f52ca68",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 - Download Jira data\n",
    "We download data if they are not already present in the data folder.\n",
    "\n",
    "Return the dataframe of the data.\n",
    "\n",
    "Query filter can be defined in config.ini"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4971d821b405286",
   "metadata": {},
   "source": [
    "jira_dataframe = jira_download()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8f051f67cbe342b",
   "metadata": {},
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "Previously, we downloaded all the data from Jira. Now, we will clean the data using pandas.\n",
    "We will keep only some columns and combine some columns."
   ]
  },
  {
   "cell_type": "code",
   "id": "b6c04fde21e36891",
   "metadata": {},
   "source": [
    "keep: [str] = ['Issue key', 'Status', 'Resolution', 'Created', 'Fix Versions Combined', 'Affects Versions Combined']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d3d14c6e651890b",
   "metadata": {},
   "source": [
    "affects_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1571fc3d63fa3d49",
   "metadata": {},
   "source": [
    "# Combine the versions into a single column\n",
    "fix_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "jira_dataframe['Fix Versions Combined'] = jira_dataframe[fix_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")\n",
    "jira_dataframe = jira_dataframe.loc[:, keep]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7229ab85b247aa84",
   "metadata": {},
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns: Index = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values: ndarray = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys: ndarray = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "ids: set = set(flattened_issue_keys)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c56c59729f4f2bd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Part 2 : Repository analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "af5c65ce22975fa2",
   "metadata": {},
   "source": [
    "from Hive import git_download, commit_analysis, update_commit_dataframe\n",
    "from git import Repo, Tag\n",
    "from pandas import DataFrame\n",
    "from configparser import ConfigParser\n",
    "from re import compile\n",
    "from packaging import version"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c7e1094fe45f12b",
   "metadata": {},
   "source": [
    "### 2.1 - Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "id": "da70cec527312bb6",
   "metadata": {},
   "source": [
    "repo: Repo = git_download()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "440e0445aebd0288",
   "metadata": {},
   "source": [
    "all_couples = commit_analysis(ids)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc716ced26d7531a",
   "metadata": {},
   "source": [
    "### 2.2 - Filter data"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bac11954b2066d9",
   "metadata": {},
   "source": [
    "commit_dataframe: DataFrame = DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90c98946d2120458",
   "metadata": {},
   "source": [
    "# Languages without whitespaces\n",
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "languages: [str] = config[\"GENERAL\"][\"Languages\"].split(\",\")\n",
    "languages: [str] = [lang.strip() for lang in languages]\n",
    "commit_dataframe: DataFrame = commit_dataframe[commit_dataframe['File'].str.endswith(tuple(languages))]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c9ce9d7-7636-45b4-826a-f55535ef28a3",
   "metadata": {},
   "source": [
    "couples = update_commit_dataframe(commit_dataframe, jira_dataframe)\n",
    "couples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f496352e0c7a43f5",
   "metadata": {},
   "source": [
    "### 2.3 - Extract filter versions from git"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab6fbf64ca7a8f6f",
   "metadata": {},
   "source": [
    "releases_regex: [str] = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "tags: Tag = repo.tags\n",
    "versions: dict = {tag.name: tag.commit for tag in tags}\n",
    "releases_regex: [str] = [regex.strip() for regex in releases_regex]\n",
    "releases_regex = [compile(regex) for regex in releases_regex]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418d3b719f004c46",
   "metadata": {},
   "source": [
    "filtered_versions: dict = {}\n",
    "for version_str in versions:\n",
    "    if any(regex.match(version_str) for regex in releases_regex):\n",
    "        version_numbers = version_str.split(\"-\")[1]\n",
    "        if version.parse(version_numbers) >= version.parse(\"2.0\"):\n",
    "            filtered_versions[version_numbers] = versions[version_str]\n",
    "\n",
    "filtered_versions = dict(sorted(\n",
    "    filtered_versions.items(),\n",
    "    key=lambda item: item[1].committed_datetime,\n",
    "    reverse=True\n",
    "))\n",
    "\n",
    "filtered_versions, len(filtered_versions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bda8a7e729d746e",
   "metadata": {},
   "source": [
    "## Part 3. - Understand analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "341333382b3f4712",
   "metadata": {},
   "source": [
    "from Understand.commands import und_create_command, und_purge_command\n",
    "from Understand.metrics import metrics\n",
    "from Understand.label import label_all_metrics\n",
    "from Understand.enrich import enrich_metrics\n",
    "from Understand.update import merge_all_metrics\n",
    "from os import path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa8504cac8b12909",
   "metadata": {},
   "source": [
    "### 3.1 - Create the Understand project\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e897f593172bee81",
   "metadata": {},
   "source": [
    "hive_git_directory: str = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "data_directory: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "understand_project_name: str = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "\n",
    "understand_project_path: str = path.join(data_directory, hive_git_directory, understand_project_name)\n",
    "\n",
    "if not path.exists(understand_project_path):\n",
    "    und_create_command()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90fadd76a26bddbb",
   "metadata": {},
   "source": [
    "und_purge_command()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b6e1f947-5bde-4984-8adc-86b859a1ad59",
   "metadata": {},
   "source": [
    "### 3.2 - Metrics extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41dab79156306ac6",
   "metadata": {},
   "source": [
    "metrics(filtered_versions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2aa23e7-801e-469e-a10d-9bea94b91aff",
   "metadata": {},
   "source": [
    "### 3.3 - Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b78f4b34-6a24-4a64-b04a-e20bb44a1473",
   "metadata": {},
   "source": [
    "label_all_metrics(couples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58378aec2b68434e",
   "metadata": {},
   "source": [
    "enrich_metrics(couples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7db9b08e86a884f1",
   "metadata": {},
   "source": [
    "v = [\n",
    "    \"2.0.0\", \"2.0.1\", \"2.1.0\", \"2.1.1\", \"2.2.0\", \"2.3.0\", \"2.3.1\", \"2.3.2\",\n",
    "    \"2.3.3\", \"2.3.4\", \"2.3.5\", \"2.3.6\", \"2.3.7\", \"2.3.8\", \"2.3.9\", \"2.3.10\",\n",
    "    \"3.0.0\", \"3.1.0\", \"3.1.1\", \"3.1.2\", \"3.1.3\", \"4.0.0\", \"4.0.1\"\n",
    "]\n",
    "merge_all_metrics(v)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 3.B Adding new metrics\n"
   ],
   "id": "209563e761709501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from git import Repo\n",
    "import pydriller\n",
    "import importlib\n",
    "my_metrics = importlib.import_module(\"projet.leo.metrics\")\n",
    "\n",
    "\n",
    "from projet.leo import get_versions\n",
    "from Objects.Version import Version\n",
    "from IA_models import load_data\n",
    "\n",
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "DATA_DIRECTORY: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "LABELED_METRICS_OUTPUT_DIRECTORY: str = os.path.join(DATA_DIRECTORY, config[\"OUTPUT\"][\"LabeledMetricsOutputDirectory\"])\n",
    "data_dict: dict = load_data(LABELED_METRICS_OUTPUT_DIRECTORY)"
   ],
   "id": "e39809efa6ecbe15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "versions = get_versions(repo)  # Create version and link them together",
   "id": "c1d7cc8908490dbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "my_metrics = importlib.import_module(\"projet.leo.metrics\")\n",
    "time = importlib.import_module(\"projet.leo.metrics.time\")\n",
    "print(dir(my_metrics))\n",
    "for key in data_dict:\n",
    "    df = data_dict[key]\n",
    "    df[\"added_lines\"] = 0\n",
    "    df[\"deleted_lines\"] = 0\n",
    "    df[\"commit_count\"] = 0\n",
    "    df[\"commit_count_r\"] = 0\n",
    "    df[\"dev_count\"] = 0\n",
    "    df[\"dev_count_r\"] = 0\n",
    "    v = key.split(\"_\")[0].split(\".\")\n",
    "    v = Version.getVersion(tuple(map(int, v)))\n",
    "    added = my_metrics.added_lines(v)\n",
    "    deleted = my_metrics.deleted_lines(v)\n",
    "    c_count = my_metrics.commit_count(v)\n",
    "    c_count_r = my_metrics.commit_count_r(v)\n",
    "    d_count = my_metrics.dev_count(v)\n",
    "    d_count_r = my_metrics.dev_count_r(v)\n",
    "    m_time = time.mean_time(v)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row[\"Name\"]\n",
    "        if file_name in added:\n",
    "            df.at[index, \"added_lines\"] = added[file_name]\n",
    "            df.at[index, \"deleted_lines\"] = deleted[file_name]\n",
    "            df.at[index, \"commit_count\"] = c_count[file_name]\n",
    "            df.at[index, \"commit_count_r\"] = c_count_r[file_name]\n",
    "            df.at[index, \"dev_count\"] = d_count[file_name]\n",
    "            df.at[index, \"dev_count_r\"] = d_count_r[file_name]\n",
    "\n",
    "    print(df.head(5))\n"
   ],
   "id": "8e6baa071d5c3c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20d9cb35967e9b16",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from IA_models import load_data, KFold_XY, plot_SHAP, plot_AUC, \\\n",
    "    plot_recall, plot_precision, generate_model_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "735f815b39513eb6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.1 - Pipeline Learning Model\n",
    "#### 4.1.1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "id": "1499cec07957d7c0",
   "metadata": {},
   "source": [
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "DATA_DIRECTORY: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "LABELED_METRICS_OUTPUT_DIRECTORY: str = os.path.join(DATA_DIRECTORY, config[\"OUTPUT\"][\"LabeledMetricsOutputDirectory\"])\n",
    "N_SPLITS: int = int(config[\"IA\"][\"NSplits\"])\n",
    "SHUFFLE: bool = config[\"IA\"].getboolean(\"Shuffle\")\n",
    "RANDOM_STATE: int = int(config[\"IA\"][\"RandomState\"])\n",
    "N_ESTIMATORS: int = int(config[\"IA\"][\"nEstimators\"])\n",
    "\n",
    "data_dict: dict = load_data(LABELED_METRICS_OUTPUT_DIRECTORY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6194cbdc20dd73b1",
   "metadata": {},
   "source": [
    "#### 4.1.2 - Prepare data\n",
    "The commit version, its ID, and the file name are not considered in the model training. All columns containing a NaN are unusable and removed."
   ]
  },
  {
   "cell_type": "code",
   "id": "90f485209526e183",
   "metadata": {},
   "source": [
    "XY_dict: dict = {}\n",
    "for key in data_dict.keys():\n",
    "    data: pd.DataFrame = data_dict[key]\n",
    "    X = data.drop(columns=['BugStatus', 'Name']).dropna(axis=1)  # independent variables\n",
    "    y = data['BugStatus']  # presence of a bug\n",
    "    XY_dict[key] = (X, y)\n",
    "XY_dict.keys()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dfee05b88ca0a8cf",
   "metadata": {},
   "source": [
    "#### 4.1.3 Training and test data\n",
    "The entire dataset is divided into 10 equal parts on which the model is trained. Validation is performed [using cross-validation](https://medium.com/@tubelwj/five-methods-for-data-splitting-in-machine-learning-27baa50908ed) to more accurately determine the effectiveness of our model."
   ]
  },
  {
   "cell_type": "code",
   "id": "4006a01093b96757",
   "metadata": {},
   "source": [
    "XY_training_dict: dict = {}\n",
    "XY_testing_dict: dict = {}\n",
    "for key in XY_dict.keys():\n",
    "    X, y = XY_dict[key]\n",
    "    X_train, X_test, y_train, y_test = KFold_XY(N_SPLITS, SHUFFLE, RANDOM_STATE, X, y)\n",
    "    XY_training_dict[key] = (X_train, y_train)\n",
    "    XY_testing_dict[key] = (X_test, y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb4ad7d610a666b2",
   "metadata": {},
   "source": [
    "### 4.1.4 Model Training\n",
    "\n",
    "Comparison between logistic regression and random forest."
   ]
  },
  {
   "cell_type": "code",
   "id": "8b6c0836480bbeb",
   "metadata": {},
   "source": [
    "logistic_regression_models: dict = {}\n",
    "random_forest_models: dict = {}\n",
    "\n",
    "for key in XY_training_dict:\n",
    "    X_train, y_train = XY_training_dict[key]\n",
    "    log_model = LogisticRegression(max_iter=20_000_000)\n",
    "    random_model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "\n",
    "    log_model.fit(X_train, y_train)\n",
    "    random_model.fit(X_train, y_train)\n",
    "\n",
    "    logistic_regression_models[key] = log_model\n",
    "    random_forest_models[key] = random_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d80f2b14cab76a2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2 - Evaluation of the model performance\n",
    "#### 4.2.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5156c1f798310b9",
   "metadata": {},
   "source": [
    "logistic_regression_predictions: dict = {}\n",
    "random_forest_prediction: dict = {}\n",
    "\n",
    "for key in XY_testing_dict:\n",
    "    X_test, y_test = XY_testing_dict[key]\n",
    "    random_forest_prediction[key] = random_forest_models[key].predict(X_test)\n",
    "    logistic_regression_predictions[key] = logistic_regression_models[key].predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e0b897fd98d7a26",
   "metadata": {},
   "source": [
    "#### 4.2.2 Evaluation\n",
    "\n",
    "The 2 models are compared by their AUC, precision, and recall. The **random forest** is a better model for determining the presence of bugs in a commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3663b95faa359",
   "metadata": {},
   "source": [
    "##### AUC"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb2ad75f6b5cb352",
   "metadata": {},
   "source": [
    "y_test: dict = {key: XY_testing_dict[key][1] for key in XY_testing_dict.keys()}\n",
    "y_pred_log: dict = {key: logistic_regression_predictions[key] for key in logistic_regression_predictions.keys()}\n",
    "y_pred_rf: dict = {key: random_forest_prediction[key] for key in random_forest_prediction.keys()}\n",
    "plot_AUC(y_test, y_pred_log, y_pred_rf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fe7114ce10866d31",
   "metadata": {},
   "source": [
    "##### recall"
   ]
  },
  {
   "cell_type": "code",
   "id": "d362d645b0314039",
   "metadata": {},
   "source": [
    "plot_recall(y_test, y_pred_log, y_pred_rf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81ad8bf0437fcfff",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e6488c53fe70fe5",
   "metadata": {},
   "source": [
    "plot_precision(y_test, y_pred_log, y_pred_rf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76a81f387f49d9ef",
   "metadata": {},
   "source": [
    "##### Report"
   ]
  },
  {
   "cell_type": "code",
   "id": "e4d10ac5a8ce1e22",
   "metadata": {},
   "source": [
    "generate_model_report(y_test, y_pred_log, y_pred_rf)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d6f15b69acee02d",
   "metadata": {},
   "source": [
    "##### SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "id": "48af0e509cdede2d",
   "metadata": {},
   "source": [
    "shap_values_versions = {}\n",
    "for key in logistic_regression_models:\n",
    "    shap_values = plot_SHAP(logistic_regression_models[key], XY_training_dict[key][0], XY_testing_dict[key][0], key)\n",
    "    shap_values_versions[key] = shap_values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75bfbc71e0a89acb",
   "metadata": {},
   "source": [
    "### 4.3 - Actions to take\n",
    "#### 4.3.1 Reduce code complexity\n",
    "`CountLineCode` and `CountStmtExe` are important variables for bug prediction. Indeed, the larger the `CountLineCode` and `CountStmtExe`, the more likely the presence of a bug in the file.\n",
    "\n",
    "**Solution**: Adopt a modular architecture.\n",
    "\n",
    "**Example**: HiveConf.java contained 3249 lines of code and 676 statements in release-2.0.0. It could be broken down into several modules, even if these modules exist but have few lines of code (HiveConfUtil.java which contains 8 lines of code and 5 statements)."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a192ba089bf1b99",
   "metadata": {},
   "source": [
    "versions: list = list(data_dict.keys())\n",
    "print(versions[0])\n",
    "data_2_0_0 = data_dict[versions[0]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = data_2_0_0['BugStatus'].map({0: 'blue', 1: 'red'})  # BugStatus=1 en rouge, 0 en bleu\n",
    "plt.scatter(data_2_0_0['CountLineCode'], data_2_0_0['CountStmtExe'], c=colors, alpha=0.8, edgecolors='k')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('CountLineCode (log scale)')\n",
    "plt.ylabel('CountStmtExe (log scale)')\n",
    "plt.title('Relation entre CountLineCode, CountStmtExe et BugStatus')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.scatter([], [], c='red', label='BugStatus = 1', alpha=0.8, edgecolors='k')\n",
    "plt.scatter([], [], c='blue', label='BugStatus = 0', alpha=0.8, edgecolors='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acaf38c829059144",
   "metadata": {},
   "source": [
    "#### 4.3.2. Promote better code readability\n",
    "CountLines is an important variable. The larger the CountLines, the more likely the presence of a bug in the file.  Solution: Uniformly format the code (adhere to coding standards), add relevant and concise comments, simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "id": "aa6f023b90c3c3d4",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 1))\n",
    "colors = data_2_0_0['BugStatus'].map({0: 'blue', 1: 'red'})  # BugStatus=1 en rouge, 0 en bleu\n",
    "plt.scatter(data_2_0_0['CountLine'], data_2_0_0['BugStatus'], c=colors, alpha=0.8, edgecolors='k')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('CountLine')\n",
    "plt.ylabel('BugStatus')\n",
    "plt.title('Relation entre CountLine et BugStatus')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "935a18f9bf685f38",
   "metadata": {},
   "source": [
    "#### 4.3.3. Eliminate unnecessary declarations\n",
    "CountStmtDecl indicates an excess of variables.  Solution: Remove unnecessary variables, methods, and classes, and reuse already declared variables, methods, and classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "7d8e4e5addf234be",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 1))\n",
    "colors = data_2_0_0['BugStatus'].map({0: 'blue', 1: 'red'})  # BugStatus=1 en rouge, 0 en bleu\n",
    "plt.scatter(data_2_0_0['CountStmtDecl'], data_2_0_0['BugStatus'], c=colors, alpha=0.8, edgecolors='k')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('CountStmtDecl')\n",
    "plt.ylabel('BugStatus')\n",
    "plt.title('Relation entre CountStmtDecl et BugStatus')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b5a7af3b7098896",
   "metadata": {},
   "source": [
    "#### 4.3.4. Keep logs for each execution\n",
    "CountStmtExe is an important variable. This indicates that most bugs come from executable statements.  Solution: Adopt logging in all files containing executable statements.  Example: TSetIpAddressProcessor.java contains logging and has no bugs, whereas ASTBuilder.java does not have logging and has a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822c587255b86ca",
   "metadata": {},
   "source": [
    "#### 4.3.5. Develop and automate more tests\n",
    "Given the importance of `CountStmtExe`, this may require more unit tests.\n",
    "\n",
    "**Solution**: Improve test coverage by automating them for each commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ef3e142ef1b81",
   "metadata": {},
   "source": [
    "## 5 - Evolution of the most important metrics by version"
   ]
  },
  {
   "cell_type": "code",
   "id": "334c6b4d2b59741c",
   "metadata": {},
   "source": [
    "best_metrics = set()\n",
    "metrics_values = {}\n",
    "for key in shap_values_versions.keys():\n",
    "    version_title = key[:3]\n",
    "    shap_values = shap_values_versions[key]\n",
    "    X_test = XY_testing_dict[key][0]\n",
    "    # Extraire les noms des features depuis X_test\n",
    "    feature_names = X_test.columns if hasattr(X_test, 'columns') else [f'Feature {i}' for i in range(X_test.shape[1])]\n",
    "    # Calculer l'importance moyenne absolue des SHAP values pour chaque feature\n",
    "    shap_mean_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "    # Trouver les indices des deux features les plus importantes\n",
    "    top_2_indices = np.argsort(shap_mean_importance)[-3:][::-1]\n",
    "    # Extraire les noms et les valeurs des deux features les plus importantes\n",
    "    top_2_features = []\n",
    "    for i in top_2_indices:\n",
    "        top_2_features.append((feature_names[i], shap_mean_importance[i]))\n",
    "        best_metrics.add(feature_names[i])\n",
    "    metrics_values[version_title] = top_2_features\n",
    "print(best_metrics)\n",
    "\n",
    "#"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7b98f808909762f",
   "metadata": {},
   "source": [
    "# Initialize a list to store the rows of the DataFrame\n",
    "rows = []\n",
    "\n",
    "for version, features in metrics_values.items():\n",
    "    row = {'version': version}\n",
    "    for metric_name, metric_value in features:\n",
    "        row[metric_name] = metric_value\n",
    "    rows.append(row)  # Ajouter la ligne Ã  la liste\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "# Fill missing values with 0 (or NaN as needed)\n",
    "df_metrics = df_metrics.fillna(0)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in best_metrics:\n",
    "    if metric in df_metrics:\n",
    "        plt.plot(\n",
    "            df_metrics['version'],\n",
    "            df_metrics[metric],\n",
    "            label=metric,\n",
    "            marker='o'\n",
    "        )\n",
    "\n",
    "# AAdd details to the graph\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Importance moyenne (SHAP)')\n",
    "plt.title('Ãvolution des mÃ©triques les plus importantes par version')\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "744e0a62-7b4f-4db2-afb1-e6ecfa6646fe",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
