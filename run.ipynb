{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa166c8f436bbb8",
   "metadata": {},
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **Léo FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc574ebf57602201",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 : Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caf94fc63fdaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:47.486316Z",
     "start_time": "2024-12-02T23:08:47.061925Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import logistic\n",
    "\n",
    "from Jira import jira_download\n",
    "from pandas import Index\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4622a84f52ca68",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 - Download Jira data\n",
    "We download data if they are not already present in the data folder.\n",
    "\n",
    "Return the dataframe of the data.\n",
    "\n",
    "Query filter can be defined in config.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4971d821b405286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:49.866978Z",
     "start_time": "2024-12-02T23:08:49.141873Z"
    }
   },
   "outputs": [],
   "source": [
    "jira_dataframe = jira_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f051f67cbe342b",
   "metadata": {},
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "Previously, we downloaded all the data from Jira. Now, we will clean the data using pandas.\n",
    "We will keep only some columns and combine some columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c04fde21e36891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:51.902178Z",
     "start_time": "2024-12-02T23:08:51.898964Z"
    }
   },
   "outputs": [],
   "source": [
    "keep: [str] = ['Issue key', 'Status', 'Resolution', 'Created', 'Fix Versions Combined', 'Affects Versions Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d14c6e651890b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:53.767027Z",
     "start_time": "2024-12-02T23:08:53.583833Z"
    }
   },
   "outputs": [],
   "source": [
    "affects_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571fc3d63fa3d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:55.618137Z",
     "start_time": "2024-12-02T23:08:55.434464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine the versions into a single column\n",
    "fix_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "jira_dataframe['Fix Versions Combined'] = jira_dataframe[fix_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")\n",
    "jira_dataframe = jira_dataframe.loc[:, keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229ab85b247aa84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:57.104798Z",
     "start_time": "2024-12-02T23:08:57.100316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns: Index = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values: ndarray = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys: ndarray = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "ids: set = set(flattened_issue_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0403d061d62191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:08:58.546192Z",
     "start_time": "2024-12-02T23:08:58.536676Z"
    }
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c59729f4f2bd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Part 2 : Repository analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c65ce22975fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:09:18.784942Z",
     "start_time": "2024-12-02T23:09:18.568401Z"
    }
   },
   "outputs": [],
   "source": [
    "from Hive import git_download, commit_analysis, update_commit_dataframe\n",
    "from git import Repo, Tag\n",
    "from pandas import DataFrame\n",
    "from configparser import ConfigParser\n",
    "from re import compile\n",
    "from packaging import version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e1094fe45f12b",
   "metadata": {},
   "source": [
    "### 2.1 - Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70cec527312bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:09:21.882810Z",
     "start_time": "2024-12-02T23:09:20.596886Z"
    }
   },
   "outputs": [],
   "source": [
    "repo: Repo = git_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e0445aebd0288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:10:00.517615Z",
     "start_time": "2024-12-02T23:09:23.356886Z"
    }
   },
   "outputs": [],
   "source": [
    "all_couples = commit_analysis(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc716ced26d7531a",
   "metadata": {},
   "source": [
    "### 2.2 - Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac11954b2066d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:11:20.726994Z",
     "start_time": "2024-12-02T23:11:20.717407Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_dataframe: DataFrame = DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c98946d2120458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:11:21.967559Z",
     "start_time": "2024-12-02T23:11:21.956790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Languages without whitespaces\n",
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "languages: [str] = config[\"GENERAL\"][\"Languages\"].split(\",\")\n",
    "languages: [str] = [lang.strip() for lang in languages]\n",
    "commit_dataframe: DataFrame = commit_dataframe[commit_dataframe['File'].str.endswith(tuple(languages))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ce9d7-7636-45b4-826a-f55535ef28a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T23:11:23.411369Z",
     "start_time": "2024-12-02T23:11:23.391444Z"
    }
   },
   "outputs": [],
   "source": [
    "couples = update_commit_dataframe(commit_dataframe, jira_dataframe)\n",
    "couples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_3_files = couples[couples[\"Version Affected\"].str.contains(\"3.0.0\", na=False)]\n",
    "\n",
    "num_files = version_3_files[\"File\"].nunique()\n",
    "num_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496352e0c7a43f5",
   "metadata": {},
   "source": [
    "### 2.3 - Extract filter versions from git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6fbf64ca7a8f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:36.306044Z",
     "start_time": "2024-12-02T03:43:36.104251Z"
    }
   },
   "outputs": [],
   "source": [
    "releases_regex: [str] = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "tags: Tag = repo.tags\n",
    "versions: dict = {tag.name: tag.commit for tag in tags}\n",
    "releases_regex: [str] = [regex.strip() for regex in releases_regex]\n",
    "releases_regex = [compile(regex) for regex in releases_regex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d3b719f004c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:36.389624Z",
     "start_time": "2024-12-02T03:43:36.370125Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_versions: dict = {}\n",
    "for version_str in versions:\n",
    "    if any(regex.match(version_str) for regex in releases_regex):\n",
    "        version_numbers = version_str.split(\"-\")[1]\n",
    "        if version.parse(version_numbers) >= version.parse(\"2.0\"):\n",
    "            filtered_versions[version_numbers] = versions[version_str]\n",
    "\n",
    "filtered_versions = dict(sorted(\n",
    "    filtered_versions.items(),\n",
    "    key=lambda item: item[1].committed_datetime,\n",
    "    reverse=True\n",
    "))\n",
    "\n",
    "filtered_versions, len(filtered_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda8a7e729d746e",
   "metadata": {},
   "source": [
    "## Part 3. - Understand analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341333382b3f4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:36.581377Z",
     "start_time": "2024-12-02T03:43:36.557418Z"
    }
   },
   "outputs": [],
   "source": [
    "from Understand.commands import und_create_command, und_purge_command\n",
    "from Understand.metrics import metrics\n",
    "from Understand.label import label_all_metrics\n",
    "from os import path\n",
    "from Understand.enrich import enrich_metrics\n",
    "from Understand.update import merge_all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8504cac8b12909",
   "metadata": {},
   "source": [
    "### 3.1 - Create the Understand project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897f593172bee81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:36.718154Z",
     "start_time": "2024-12-02T03:43:36.709074Z"
    }
   },
   "outputs": [],
   "source": [
    "hive_git_directory: str = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "data_directory: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "understand_project_name: str = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "\n",
    "understand_project_path: str = path.join(data_directory, hive_git_directory, understand_project_name)\n",
    "\n",
    "if not path.exists(understand_project_path):\n",
    "    und_create_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fadd76a26bddbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:39.413583Z",
     "start_time": "2024-12-02T03:43:36.760452Z"
    }
   },
   "outputs": [],
   "source": [
    "und_purge_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1f947-5bde-4984-8adc-86b859a1ad59",
   "metadata": {},
   "source": [
    "### 3.2 - Metrics extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab79156306ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:43:39.431260Z",
     "start_time": "2024-12-02T03:43:39.418868Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics(filtered_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa23e7-801e-469e-a10d-9bea94b91aff",
   "metadata": {},
   "source": [
    "### 3.3 - Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f4b34-6a24-4a64-b04a-e20bb44a1473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:47:13.610187Z",
     "start_time": "2024-12-02T03:47:13.464063Z"
    }
   },
   "outputs": [],
   "source": [
    "label_all_metrics(couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_metrics(couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [\n",
    "    \"2.0.0\", \"2.0.1\", \"2.1.0\", \"2.1.1\", \"2.2.0\", \"2.3.0\", \"2.3.1\", \"2.3.2\",\n",
    "    \"2.3.3\", \"2.3.4\", \"2.3.5\", \"2.3.6\", \"2.3.7\", \"2.3.8\", \"2.3.9\", \"2.3.10\",\n",
    "    \"3.0.0\", \"3.1.0\", \"3.1.1\", \"3.1.2\", \"3.1.3\", \"4.0.0\", \"4.0.1\"\n",
    "]\n",
    "merge_all_metrics(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9ad0db8b384bd",
   "metadata": {},
   "source": [
    "## 4 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9cb35967e9b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:00:37.292828Z",
     "start_time": "2024-12-03T03:00:37.287719Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from configparser import ConfigParser\n",
    "from IA_models import load_data, KFold_XY, plot_SHAP, logistic_regression_treatment, random_forest_treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f815b39513eb6",
   "metadata": {},
   "source": [
    "### 4.1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499cec07957d7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:40.607439Z",
     "start_time": "2024-12-03T02:51:40.393474Z"
    }
   },
   "outputs": [],
   "source": [
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "LABELED_METRICS_OUTPUT_DIRECTORY: str = config[\"OUTPUT\"][\"LabeledMetricsOutputDirectory\"]\n",
    "N_SPLITS: int = int(config[\"IA\"][\"NSplits\"])\n",
    "SHUFFLE: bool = config[\"IA\"].getboolean(\"Shuffle\")\n",
    "RANDOM_STATE: int = int(config[\"IA\"][\"RandomState\"])\n",
    "N_ESTIMATORS: int = int(config[\"IA\"][\"nEstimators\"])\n",
    "\n",
    "data_dict: dict = load_data(LABELED_METRICS_OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194cbdc20dd73b1",
   "metadata": {},
   "source": [
    "### 4.2 - Prepare data\n",
    "The commit version, its ID, and the file name are not considered in the model training. All columns containing a NaN are unusable and removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f485209526e183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:40.886436Z",
     "start_time": "2024-12-03T02:51:40.858373Z"
    }
   },
   "outputs": [],
   "source": [
    "XY_dict: dict = {}\n",
    "for key in data_dict.keys():\n",
    "    data: pd.DataFrame = data_dict[key]\n",
    "    X = data.drop(columns=['BugStatus', 'Name', 'Kind']).dropna(axis=1)  # independent variables\n",
    "    y = data['BugStatus']  # presence of a bug\n",
    "    XY_dict[key] = (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee05b88ca0a8cf",
   "metadata": {},
   "source": [
    "### 4.3 Training and test data\n",
    "The entire dataset is divided into 10 equal parts on which the model is trained. Validation is performed [using cross-validation](https://medium.com/@tubelwj/five-methods-for-data-splitting-in-machine-learning-27baa50908ed) to more accurately determine the effectiveness of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006a01093b96757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:40.967072Z",
     "start_time": "2024-12-03T02:51:40.901734Z"
    }
   },
   "outputs": [],
   "source": [
    "XY_training_dict: dict = {}\n",
    "XY_testing_dict: dict = {}\n",
    "for key in XY_dict.keys():\n",
    "    X, y = XY_dict[key]\n",
    "    X_train, X_test, y_train, y_test = KFold_XY(N_SPLITS, SHUFFLE, RANDOM_STATE, X, y)\n",
    "    XY_training_dict[key] = (X_train, y_train)\n",
    "    XY_testing_dict[key] = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ad7d610a666b2",
   "metadata": {},
   "source": [
    "### 4.4 Model Training\n",
    "\n",
    "Comparison between logistic regression and random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b5714c749775f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:41.037183Z",
     "start_time": "2024-12-03T02:51:41.031521Z"
    }
   },
   "outputs": [],
   "source": [
    "XY_training_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651f439b933c455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:41.113545Z",
     "start_time": "2024-12-03T02:51:41.097913Z"
    }
   },
   "outputs": [],
   "source": [
    "XY_training_dict['2.0.0_labeled_metrics.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c0836480bbeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:57.933986Z",
     "start_time": "2024-12-03T02:51:41.190048Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression_models: dict = {}\n",
    "random_forest_models: dict = {}\n",
    "\n",
    "for key in XY_training_dict:\n",
    "    X_train, y_train = XY_training_dict[key]\n",
    "    log_model = LogisticRegression(max_iter=1000)\n",
    "    random_model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "\n",
    "    log_model.fit(X_train, y_train)\n",
    "    random_model.fit(X_train, y_train)\n",
    "\n",
    "    logistic_regression_models[key] = log_model\n",
    "    random_forest_models[key] = random_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f2b14cab76a2e",
   "metadata": {},
   "source": [
    "### 4.5 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5156c1f798310b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:58.046299Z",
     "start_time": "2024-12-03T02:51:57.978731Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_regression_predictions: dict = {}\n",
    "random_forest_prediction: dict = {}\n",
    "\n",
    "for key in XY_testing_dict:\n",
    "    X_test, y_test = XY_testing_dict[key]\n",
    "    random_forest_prediction[key] = random_forest_models[key].predict(X_test)\n",
    "    logistic_regression_predictions[key] = logistic_regression_models[key].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b897fd98d7a26",
   "metadata": {},
   "source": [
    "### 4.6 Evaluate the model performance\n",
    "\n",
    "The 2 models are compared by their AUC, precision, and recall. The **random forest** is a better model for determining the presence of bugs in a commit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f15b69acee02d",
   "metadata": {},
   "source": [
    "#### 4.6.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af0e509cdede2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:51:59.854207Z",
     "start_time": "2024-12-03T02:51:58.091862Z"
    }
   },
   "outputs": [],
   "source": [
    "shap_values_versions = {}\n",
    "for key in logistic_regression_models:\n",
    "    shap_values = plot_SHAP(logistic_regression_models[key], XY_training_dict[key][0], XY_testing_dict[key][0], key)\n",
    "    shap_values_versions[key] = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c6b4d2b59741c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:07:35.188183Z",
     "start_time": "2024-12-03T03:07:35.180991Z"
    }
   },
   "outputs": [],
   "source": [
    "best_metrics = set()\n",
    "metrics_values = {}\n",
    "for key in shap_values_versions.keys():\n",
    "    version_title = key[:3]\n",
    "    shap_values = shap_values_versions[key]\n",
    "    X_test = XY_testing_dict[key][0]\n",
    "    # Extraire les noms des features depuis X_test\n",
    "    feature_names = X_test.columns if hasattr(X_test, 'columns') else [f'Feature {i}' for i in range(X_test.shape[1])]\n",
    "    # Calculer l'importance moyenne absolue des SHAP values pour chaque feature\n",
    "    shap_mean_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "    # Trouver les indices des deux features les plus importantes\n",
    "    top_2_indices = np.argsort(shap_mean_importance)[-5:][::-1]\n",
    "    # Extraire les noms et les valeurs des deux features les plus importantes\n",
    "    top_2_features = []\n",
    "    for i in top_2_indices:\n",
    "        top_2_features.append((feature_names[i], shap_mean_importance[i]))\n",
    "        best_metrics.add(feature_names[i])\n",
    "    metrics_values[version_title] = top_2_features\n",
    "print(best_metrics)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af3b2bceeeb669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:07:36.154422Z",
     "start_time": "2024-12-03T03:07:35.819399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Créer un DataFrame pour organiser les données\n",
    "df_metrics = pd.DataFrame(columns=['version'] + list(best_metrics))\n",
    "for version, features in metrics_values.items():\n",
    "    row = {'version': version}\n",
    "    for metric_name, metric_value in features:\n",
    "        row[metric_name] = metric_value\n",
    "    df_metrics = pd.concat([df_metrics, pd.DataFrame([row])], ignore_index=True)\n",
    "df_metrics = df_metrics.fillna(0)\n",
    "\n",
    "# Tracer le graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in best_metrics:\n",
    "    if metric in df_metrics:\n",
    "        plt.plot(\n",
    "            df_metrics['version'],\n",
    "            df_metrics[metric],\n",
    "            label=metric,\n",
    "            marker='o'\n",
    "        )\n",
    "\n",
    "# Ajouter des détails au graphique\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Importance moyenne (SHAP)')\n",
    "plt.title('Évolution des métriques les plus importantes par version')\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarder et afficher le graphique\n",
    "plt.savefig('metrics_evolution_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b98f808909762f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
