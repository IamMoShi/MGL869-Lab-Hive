{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa166c8f436bbb8",
   "metadata": {},
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **Léo FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc574ebf57602201",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 : Data collection"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5caf94fc63fdaf4",
   "metadata": {},
   "source": [
    "from numpy.random import logistic\n",
    "\n",
    "from Jira import jira_download\n",
    "from pandas import Index\n",
    "from numpy import ndarray"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af4622a84f52ca68",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 - Download Jira data\n",
    "We download data if they are not already present in the data folder.\n",
    "\n",
    "Return the dataframe of the data.\n",
    "\n",
    "Query filter can be defined in config.ini"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4971d821b405286",
   "metadata": {},
   "source": [
    "jira_dataframe = jira_download()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8f051f67cbe342b",
   "metadata": {},
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "Previously, we downloaded all the data from Jira. Now, we will clean the data using pandas.\n",
    "We will keep only some columns and combine some columns."
   ]
  },
  {
   "cell_type": "code",
   "id": "b6c04fde21e36891",
   "metadata": {},
   "source": [
    "keep: [str] = ['Issue key', 'Status', 'Resolution', 'Created', 'Fix Versions Combined', 'Affects Versions Combined']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d3d14c6e651890b",
   "metadata": {},
   "source": [
    "affects_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1571fc3d63fa3d49",
   "metadata": {},
   "source": [
    "# Combine the versions into a single column\n",
    "fix_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "jira_dataframe['Fix Versions Combined'] = jira_dataframe[fix_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")\n",
    "jira_dataframe = jira_dataframe.loc[:, keep]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7229ab85b247aa84",
   "metadata": {},
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns: Index = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values: ndarray = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys: ndarray = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "ids: set = set(flattened_issue_keys)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ids",
   "id": "fc0403d061d62191",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c56c59729f4f2bd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Part 2 : Repository analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "af5c65ce22975fa2",
   "metadata": {},
   "source": [
    "from Hive import git_download, commit_analysis, update_commit_dataframe\n",
    "from git import Repo, Tag\n",
    "from pandas import DataFrame\n",
    "from configparser import ConfigParser\n",
    "from re import compile\n",
    "from packaging import version"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c7e1094fe45f12b",
   "metadata": {},
   "source": [
    "### 2.1 - Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "id": "da70cec527312bb6",
   "metadata": {},
   "source": [
    "repo: Repo = git_download()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "440e0445aebd0288",
   "metadata": {},
   "source": [
    "all_couples = commit_analysis(ids)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc716ced26d7531a",
   "metadata": {},
   "source": [
    "### 2.2 - Filter data"
   ]
  },
  {
   "cell_type": "code",
   "id": "6bac11954b2066d9",
   "metadata": {},
   "source": [
    "commit_dataframe: DataFrame = DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90c98946d2120458",
   "metadata": {},
   "source": [
    "# Languages without whitespaces\n",
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "languages: [str] = config[\"GENERAL\"][\"Languages\"].split(\",\")\n",
    "languages: [str] = [lang.strip() for lang in languages]\n",
    "commit_dataframe: DataFrame = commit_dataframe[commit_dataframe['File'].str.endswith(tuple(languages))]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c9ce9d7-7636-45b4-826a-f55535ef28a3",
   "metadata": {},
   "source": [
    "couples = update_commit_dataframe(commit_dataframe, jira_dataframe)\n",
    "couples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f496352e0c7a43f5",
   "metadata": {},
   "source": [
    "### 2.3 - Extract filter versions from git"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab6fbf64ca7a8f6f",
   "metadata": {},
   "source": [
    "releases_regex: [str] = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "tags: Tag = repo.tags\n",
    "versions: dict = {tag.name: tag.commit for tag in tags}\n",
    "releases_regex: [str] = [regex.strip() for regex in releases_regex]\n",
    "releases_regex = [compile(regex) for regex in releases_regex]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418d3b719f004c46",
   "metadata": {},
   "source": [
    "filtered_versions: dict = {}\n",
    "for version_str in versions:\n",
    "    if any(regex.match(version_str) for regex in releases_regex):\n",
    "        version_numbers = version_str.split(\"-\")[1]\n",
    "        if version.parse(version_numbers) >= version.parse(\"2.0\"):\n",
    "            filtered_versions[version_numbers] = versions[version_str]\n",
    "\n",
    "filtered_versions = dict(sorted(\n",
    "    filtered_versions.items(),\n",
    "    key=lambda item: item[1].committed_datetime,\n",
    "    reverse=True\n",
    "))\n",
    "\n",
    "filtered_versions, len(filtered_versions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bda8a7e729d746e",
   "metadata": {},
   "source": [
    "## Part 3. - Understand analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "341333382b3f4712",
   "metadata": {},
   "source": [
    "from Understand.commands import und_create_command, und_purge_command\n",
    "from Understand.metrics import metrics\n",
    "from Understand.label import label_all_metrics\n",
    "from Understand.enrich import enrich_metrics\n",
    "from Understand.update import merge_all_metrics\n",
    "from os import path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa8504cac8b12909",
   "metadata": {},
   "source": [
    "### 3.1 - Create the Understand project\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e897f593172bee81",
   "metadata": {},
   "source": [
    "hive_git_directory: str = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "data_directory: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "understand_project_name: str = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "\n",
    "understand_project_path: str = path.join(data_directory, hive_git_directory, understand_project_name)\n",
    "\n",
    "if not path.exists(understand_project_path):\n",
    "    und_create_command()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90fadd76a26bddbb",
   "metadata": {},
   "source": [
    "und_purge_command()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b6e1f947-5bde-4984-8adc-86b859a1ad59",
   "metadata": {},
   "source": [
    "### 3.2 - Metrics extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "41dab79156306ac6",
   "metadata": {},
   "source": [
    "metrics(filtered_versions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2aa23e7-801e-469e-a10d-9bea94b91aff",
   "metadata": {},
   "source": [
    "### 3.3 - Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b78f4b34-6a24-4a64-b04a-e20bb44a1473",
   "metadata": {},
   "source": [
    "label_all_metrics(couples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "enrich_metrics(couples)",
   "id": "58378aec2b68434e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "v = [\n",
    "    \"2.0.0\", \"2.0.1\", \"2.1.0\", \"2.1.1\", \"2.2.0\", \"2.3.0\", \"2.3.1\", \"2.3.2\",\n",
    "    \"2.3.3\", \"2.3.4\", \"2.3.5\", \"2.3.6\", \"2.3.7\", \"2.3.8\", \"2.3.9\", \"2.3.10\",\n",
    "    \"3.0.0\", \"3.1.0\", \"3.1.1\", \"3.1.2\", \"3.1.3\", \"4.0.0\", \"4.0.1\"\n",
    "]\n",
    "merge_all_metrics(v)"
   ],
   "id": "7db9b08e86a884f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 4 - Model"
   ],
   "id": "f0d9ad0db8b384bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from IA_models import load_data, KFold_XY, plot_SHAP, logistic_regression_treatment, random_forest_treatment, plot_AUC, \\\n",
    "    plot_recall, plot_precision, generate_model_report"
   ],
   "id": "20d9cb35967e9b16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### 4.1 - Pipeline Learning Model\n",
    "#### 4.1.1 - Load data"
   ],
   "id": "735f815b39513eb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "LABELED_METRICS_OUTPUT_DIRECTORY: str = config[\"OUTPUT\"][\"LabeledMetricsOutputDirectory\"]\n",
    "N_SPLITS: int = int(config[\"IA\"][\"NSplits\"])\n",
    "SHUFFLE: bool = config[\"IA\"].getboolean(\"Shuffle\")\n",
    "RANDOM_STATE: int = int(config[\"IA\"][\"RandomState\"])\n",
    "N_ESTIMATORS: int = int(config[\"IA\"][\"nEstimators\"])\n",
    "\n",
    "data_dict: dict = load_data(LABELED_METRICS_OUTPUT_DIRECTORY)"
   ],
   "id": "1499cec07957d7c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.1.2 - Prepare data\n",
    "The commit version, its ID, and the file name are not considered in the model training. All columns containing a NaN are unusable and removed."
   ],
   "id": "6194cbdc20dd73b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "XY_dict: dict = {}\n",
    "for key in data_dict.keys():\n",
    "    data: pd.DataFrame = data_dict[key]\n",
    "    X = data.drop(columns=['BugStatus', 'Name']).dropna(axis=1)  # independent variables\n",
    "    y = data['BugStatus']  # presence of a bug\n",
    "    XY_dict[key] = (X, y)\n",
    "XY_dict.keys()"
   ],
   "id": "90f485209526e183",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.1.3 Training and test data\n",
    "The entire dataset is divided into 10 equal parts on which the model is trained. Validation is performed [using cross-validation](https://medium.com/@tubelwj/five-methods-for-data-splitting-in-machine-learning-27baa50908ed) to more accurately determine the effectiveness of our model."
   ],
   "id": "dfee05b88ca0a8cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "XY_training_dict: dict = {}\n",
    "XY_testing_dict: dict = {}\n",
    "for key in XY_dict.keys():\n",
    "    X, y = XY_dict[key]\n",
    "    X_train, X_test, y_train, y_test = KFold_XY(N_SPLITS, SHUFFLE, RANDOM_STATE, X, y)\n",
    "    XY_training_dict[key] = (X_train, y_train)\n",
    "    XY_testing_dict[key] = (X_test, y_test)"
   ],
   "id": "4006a01093b96757",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1.4 Model Training\n",
    "\n",
    "Comparison between logistic regression and random forest."
   ],
   "id": "cb4ad7d610a666b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_models: dict = {}\n",
    "random_forest_models: dict = {}\n",
    "\n",
    "for key in XY_training_dict:\n",
    "    X_train, y_train = XY_training_dict[key]\n",
    "    log_model = LogisticRegression(max_iter=10_000_000)\n",
    "    random_model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "\n",
    "    log_model.fit(X_train, y_train)\n",
    "    random_model.fit(X_train, y_train)\n",
    "\n",
    "    logistic_regression_models[key] = log_model\n",
    "    random_forest_models[key] = random_model"
   ],
   "id": "8b6c0836480bbeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### 4.2 - Evaluation of the model performance\n",
    "#### 4.2.1 Prediction"
   ],
   "id": "d80f2b14cab76a2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_predictions: dict = {}\n",
    "random_forest_prediction: dict = {}\n",
    "\n",
    "for key in XY_testing_dict:\n",
    "    X_test, y_test = XY_testing_dict[key]\n",
    "    random_forest_prediction[key] = random_forest_models[key].predict(X_test)\n",
    "    logistic_regression_predictions[key] = logistic_regression_models[key].predict(X_test)"
   ],
   "id": "f5156c1f798310b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 4.2.2 Evaluation\n",
    "\n",
    "The 2 models are compared by their AUC, precision, and recall. The **random forest** is a better model for determining the presence of bugs in a commit."
   ],
   "id": "6e0b897fd98d7a26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### AUC",
   "id": "5ea3663b95faa359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_test: dict = {key: XY_testing_dict[key][1] for key in XY_testing_dict.keys()}\n",
    "y_pred_log: dict = {key: logistic_regression_predictions[key] for key in logistic_regression_predictions.keys()}\n",
    "y_pred_rf: dict = {key: random_forest_prediction[key] for key in random_forest_prediction.keys()}\n",
    "plot_AUC(y_test, y_pred_log, y_pred_rf)"
   ],
   "id": "cb2ad75f6b5cb352",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### recall",
   "id": "fe7114ce10866d31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_recall(y_test, y_pred_log, y_pred_rf)",
   "id": "d362d645b0314039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Precision",
   "id": "81ad8bf0437fcfff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_precision(y_test, y_pred_log, y_pred_rf)",
   "id": "8e6488c53fe70fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Report",
   "id": "76a81f387f49d9ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generate_model_report(y_test, y_pred_log, y_pred_rf)",
   "id": "e4d10ac5a8ce1e22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### SHAP values",
   "id": "9d6f15b69acee02d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shap_values_versions = {}\n",
    "for key in random_forest_models:\n",
    "    shap_values = plot_SHAP(random_forest_models[key], XY_training_dict[key][0], XY_testing_dict[key][0], key)\n",
    "    shap_values_versions[key] = shap_values"
   ],
   "id": "e6d79f7f9752ce00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "shap_values_versions = {}\n",
    "for key in logistic_regression_models:\n",
    "    shap_values = plot_SHAP(logistic_regression_models[key], XY_training_dict[key][0], XY_testing_dict[key][0], key)\n",
    "    shap_values_versions[key] = shap_values"
   ],
   "id": "48af0e509cdede2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.3 - Actions to take\n",
    "#### 4.3.1 Reduce code complexity\n",
    "`CountLineCode` and `CountStmtExe` are important variables for bug prediction. Indeed, the larger the `CountLineCode` and `CountStmtExe`, the more likely the presence of a bug in the file.\n",
    "\n",
    "**Solution**: Adopt a modular architecture.\n",
    "\n",
    "**Example**: HiveConf.java contained 3249 lines of code and 676 statements in release-2.0.0. It could be broken down into several modules, even if these modules exist but have few lines of code (HiveConfUtil.java which contains 8 lines of code and 5 statements)."
   ],
   "id": "75bfbc71e0a89acb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "12e37ed604e13dfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "versions: list = list(data_dict.keys())\n",
    "print(versions[0])\n",
    "data_2_0_0 = data_dict[versions[0]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = data_2_0_0['BugStatus'].map({0: 'blue', 1: 'red'})  # BugStatus=1 en rouge, 0 en bleu\n",
    "plt.scatter(data_2_0_0['CountLineCode'], data_2_0_0['CountStmtExe'], c=colors, alpha=0.8, edgecolors='k')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('CountLineCode (log scale)')\n",
    "plt.ylabel('CountStmtExe (log scale)')\n",
    "plt.title('Relation entre CountLineCode, CountStmtExe et BugStatus')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.scatter([], [], c='red', label='BugStatus = 1', alpha=0.8, edgecolors='k')\n",
    "plt.scatter([], [], c='blue', label='BugStatus = 0', alpha=0.8, edgecolors='k')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "8a192ba089bf1b99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5 - Evolution of the most important metrics by version",
   "id": "935ef3e142ef1b81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_metrics = set()\n",
    "metrics_values = {}\n",
    "for key in shap_values_versions.keys():\n",
    "    version_title = key[:3]\n",
    "    shap_values = shap_values_versions[key]\n",
    "    X_test = XY_testing_dict[key][0]\n",
    "    # Extraire les noms des features depuis X_test\n",
    "    feature_names = X_test.columns if hasattr(X_test, 'columns') else [f'Feature {i}' for i in range(X_test.shape[1])]\n",
    "    # Calculer l'importance moyenne absolue des SHAP values pour chaque feature\n",
    "    shap_mean_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "    # Trouver les indices des deux features les plus importantes\n",
    "    top_2_indices = np.argsort(shap_mean_importance)[-3:][::-1]\n",
    "    # Extraire les noms et les valeurs des deux features les plus importantes\n",
    "    top_2_features = []\n",
    "    for i in top_2_indices:\n",
    "        top_2_features.append((feature_names[i], shap_mean_importance[i]))\n",
    "        best_metrics.add(feature_names[i])\n",
    "    metrics_values[version_title] = top_2_features\n",
    "print(best_metrics)\n",
    "\n",
    "#"
   ],
   "id": "334c6b4d2b59741c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialiser une liste pour stocker les lignes\n",
    "rows = []\n",
    "\n",
    "for version, features in metrics_values.items():\n",
    "    row = {'version': version}\n",
    "    for metric_name, metric_value in features:\n",
    "        row[metric_name] = metric_value\n",
    "    rows.append(row)  # Ajouter la ligne à la liste\n",
    "\n",
    "# Convertir la liste de dictionnaires en DataFrame\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "# Remplir les valeurs manquantes par 0 (ou NaN selon vos besoins)\n",
    "df_metrics = df_metrics.fillna(0)\n",
    "\n",
    "# Tracer le graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in best_metrics:\n",
    "    if metric in df_metrics:\n",
    "        plt.plot(\n",
    "            df_metrics['version'],\n",
    "            df_metrics[metric],\n",
    "            label=metric,\n",
    "            marker='o'\n",
    "        )\n",
    "\n",
    "# Ajouter des détails au graphique\n",
    "plt.xlabel('Version')\n",
    "plt.ylabel('Importance moyenne (SHAP)')\n",
    "plt.title('Évolution des métriques les plus importantes par version')\n",
    "plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarder et afficher le graphique\n",
    "plt.savefig('metrics_evolution_plot.png')\n",
    "plt.show()"
   ],
   "id": "a7b98f808909762f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f313a0c1da368dba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fff46d4bd2e83777",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
