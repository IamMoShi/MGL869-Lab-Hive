{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ba9198ea3046db",
   "metadata": {},
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **Léo FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37f0a23417b4ad",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T00:04:14.445616Z",
     "start_time": "2024-11-21T00:04:13.031254Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import re\n",
    "import shutil\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "from Jira import jira_download as jira_download"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f397c103fa890c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:57.101626Z",
     "start_time": "2024-11-20T02:06:57.097012Z"
    }
   },
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "required_sections : [str] = [\n",
    "    \"GENERAL\",\n",
    "    \"GIT\",\n",
    "    \"JIRA\",\n",
    "    \"UNDERSTAND\",\n",
    "    \"OUTPUT\",\n",
    "    \"JUPYTER\"]\n",
    "\n",
    "for section in required_sections:\n",
    "    assert section in config, f\"Section {section} is missing in the configuration file\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a43a03e34f82b596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:57.314612Z",
     "start_time": "2024-11-20T02:06:57.306656Z"
    }
   },
   "source": [
    "def testConfig(t_section: str, keys : [str]):\n",
    "    assert t_section in config          , f\"Section {t_section} is missing in the configuration file\"\n",
    "    for key in keys:\n",
    "        assert key in config[t_section] , f\"Key {key} is missing in the configuration file\"\n",
    "        assert config[t_section][key]   , f\"Key {key} is empty in the configuration file\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "df29392ee535edd8",
   "metadata": {},
   "source": [
    "## Part 1 : Data collection\n",
    "\n",
    "### 1.1 - Download Jira data\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:57.777171Z",
     "start_time": "2024-11-20T02:06:57.357855Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded\n",
      "Filter = 'project=HIVE AND issuetype=Bug AND status in (Resolved, Closed) AND affectedVersion>= 2.0.0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                Summary   Issue key  Issue id  \\\n",
       "0     Iceberg: Concurrent queries fail during commit...  HIVE-28515  13591603   \n",
       "1     Outdated MetastoreSchemaTool class reference i...  HIVE-28487  13590437   \n",
       "2     JDBC: TableName matcher fix in GenericJdbcData...  HIVE-28451  13589308   \n",
       "3     Iceberg: Bucket partition transform with DECIM...  HIVE-28439  13588148   \n",
       "4      Manual import of mysql schema upgrade file fails  HIVE-28426  13587586   \n",
       "...                                                 ...         ...       ...   \n",
       "2241  OrcSplit fails to account for columnar project...   HIVE-7428  12727720   \n",
       "2242  Fix bug in HiveIndexedInputFormat implementati...   HIVE-7239  12721479   \n",
       "2243  Parse Exception : character '@' not supported ...   HIVE-4413  12644338   \n",
       "2244               Fix column names in FileSinkOperator   HIVE-4243  12639596   \n",
       "2245  Boolean columns in Hive tables containing NULL...   HIVE-1863  12493943   \n",
       "\n",
       "     Issue Type    Status Project key Project name Project type Project lead  \\\n",
       "0           Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "1           Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "2           Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "3           Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "4           Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "...         ...       ...         ...          ...          ...          ...   \n",
       "2241        Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "2242        Bug    Closed        HIVE         Hive     software     ayushtkn   \n",
       "2243        Bug  Resolved        HIVE         Hive     software     ayushtkn   \n",
       "2244        Bug    Closed        HIVE         Hive     software     ayushtkn   \n",
       "2245        Bug    Closed        HIVE         Hive     software     ayushtkn   \n",
       "\n",
       "                                    Project description  ... Comment.53  \\\n",
       "0     Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "1     Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "2     Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "3     Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "4     Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "...                                                 ...  ...        ...   \n",
       "2241  Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "2242  Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "2243  Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "2244  Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "2245  Hive is a data warehouse infrastructure built ...  ...        NaN   \n",
       "\n",
       "     Comment.54 Comment.55 Comment.56 Comment.57 Comment.58 Comment.59  \\\n",
       "0           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4           NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2241        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2242        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2243        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2244        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2245        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "     Comment.60 Comment.61 Comment.62  \n",
       "0           NaN        NaN        NaN  \n",
       "1           NaN        NaN        NaN  \n",
       "2           NaN        NaN        NaN  \n",
       "3           NaN        NaN        NaN  \n",
       "4           NaN        NaN        NaN  \n",
       "...         ...        ...        ...  \n",
       "2241        NaN        NaN        NaN  \n",
       "2242        NaN        NaN        NaN  \n",
       "2243        NaN        NaN        NaN  \n",
       "2244        NaN        NaN        NaN  \n",
       "2245        NaN        NaN        NaN  \n",
       "\n",
       "[2246 rows x 373 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Issue key</th>\n",
       "      <th>Issue id</th>\n",
       "      <th>Issue Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Project key</th>\n",
       "      <th>Project name</th>\n",
       "      <th>Project type</th>\n",
       "      <th>Project lead</th>\n",
       "      <th>Project description</th>\n",
       "      <th>...</th>\n",
       "      <th>Comment.53</th>\n",
       "      <th>Comment.54</th>\n",
       "      <th>Comment.55</th>\n",
       "      <th>Comment.56</th>\n",
       "      <th>Comment.57</th>\n",
       "      <th>Comment.58</th>\n",
       "      <th>Comment.59</th>\n",
       "      <th>Comment.60</th>\n",
       "      <th>Comment.61</th>\n",
       "      <th>Comment.62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iceberg: Concurrent queries fail during commit...</td>\n",
       "      <td>HIVE-28515</td>\n",
       "      <td>13591603</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outdated MetastoreSchemaTool class reference i...</td>\n",
       "      <td>HIVE-28487</td>\n",
       "      <td>13590437</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JDBC: TableName matcher fix in GenericJdbcData...</td>\n",
       "      <td>HIVE-28451</td>\n",
       "      <td>13589308</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceberg: Bucket partition transform with DECIM...</td>\n",
       "      <td>HIVE-28439</td>\n",
       "      <td>13588148</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manual import of mysql schema upgrade file fails</td>\n",
       "      <td>HIVE-28426</td>\n",
       "      <td>13587586</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>OrcSplit fails to account for columnar project...</td>\n",
       "      <td>HIVE-7428</td>\n",
       "      <td>12727720</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Fix bug in HiveIndexedInputFormat implementati...</td>\n",
       "      <td>HIVE-7239</td>\n",
       "      <td>12721479</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Closed</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>Parse Exception : character '@' not supported ...</td>\n",
       "      <td>HIVE-4413</td>\n",
       "      <td>12644338</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>Fix column names in FileSinkOperator</td>\n",
       "      <td>HIVE-4243</td>\n",
       "      <td>12639596</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Closed</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>Boolean columns in Hive tables containing NULL...</td>\n",
       "      <td>HIVE-1863</td>\n",
       "      <td>12493943</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Closed</td>\n",
       "      <td>HIVE</td>\n",
       "      <td>Hive</td>\n",
       "      <td>software</td>\n",
       "      <td>ayushtkn</td>\n",
       "      <td>Hive is a data warehouse infrastructure built ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2246 rows × 373 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": "jira_download()",
   "id": "8494cabba75ef4b9"
  },
  {
   "cell_type": "markdown",
   "id": "c9217dbe844954a3",
   "metadata": {},
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "#### 1.2.1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "d1cce1ee9c75dd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.136461Z",
     "start_time": "2024-11-20T02:06:57.826636Z"
    }
   },
   "source": [
    "jira_dataframe = pd.read_csv(combined_csv_path, low_memory=False)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_csv_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m jira_dataframe \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[43mcombined_csv_path\u001B[49m, low_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'combined_csv_path' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "57888f3c459618f9",
   "metadata": {},
   "source": [
    "#### 1.2.2 - Keep only the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80eda3f2af2c0baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.266040300Z",
     "start_time": "2024-11-17T20:42:09.419045Z"
    }
   },
   "outputs": [],
   "source": [
    "keep: [str] = [\n",
    "    'Issue key',\n",
    "    'Status', \n",
    "    'Resolution', \n",
    "    'Created', \n",
    "    'Fix Versions Combined', \n",
    "    'Affects Versions Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885c979912c66a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.268038700Z",
     "start_time": "2024-11-17T20:42:09.452710Z"
    }
   },
   "outputs": [],
   "source": [
    "affects_version_columns : [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "fix_version_columns     : [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "# Combine the versions into a single column\n",
    "jira_dataframe['Fix Versions Combined']     = jira_dataframe[fix_version_columns].apply(\n",
    "                                                    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    "                                                )\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "                                                    lambda x: ', '.join(x.dropna().astype(str)),  axis=1\n",
    "                                                )\n",
    "\n",
    "jira_dataframe                              = jira_dataframe.loc[:, keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1219c2c4a5a11",
   "metadata": {},
   "source": [
    "#### 1.2.3 - Extract ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156b007c777f1b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.268038700Z",
     "start_time": "2024-11-17T20:42:09.795319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issue key'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns       : pd.Index      = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values        : np.ndarray    = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys    : np.ndarray    = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "unique_issue_keys       : set           = set(flattened_issue_keys)\n",
    "# The result is a set of unique 'Issue key' values\n",
    "ids                     : set           = unique_issue_keys\n",
    "\n",
    "issue_key_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa5b6235cb5d2d",
   "metadata": {},
   "source": [
    "## Part 2 : Repository analysis\n",
    "### 2.1 - Clone repository\n",
    "#### 2.1.1 - Check configuration to run the section"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d4b6784645fa299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.269136600Z",
     "start_time": "2024-11-17T23:58:02.158457Z"
    }
   },
   "source": [
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\", \n",
    "    \"HiveGitUrl\", \n",
    "    \"HiveGitAlwaysClone\", \n",
    "    \"HiveGitAlwaysPull\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_dir            : str   = config[section][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name      : str   = config[section][\"HiveGitRepoName\"]\n",
    "hive_git_url            : str   = config[section][\"HiveGitUrl\"]\n",
    "hive_git_always_clone   : str   = config[section][\"HiveGitAlwaysClone\"]\n",
    "hive_git_always_pull    : str   = config[section][\"HiveGitAlwaysPull\"]\n",
    "\n",
    "hive_git_repo_dir       : str   = os.path.join(hive_git_dir, hive_git_repo_name)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "6ec30dd565ce4f18",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Clone repository if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9eb30c27ad733a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.269136600Z",
     "start_time": "2024-11-17T20:42:09.860379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already cloned\n",
      "Checking for updates : Pulling the repository\n"
     ]
    },
    {
     "ename": "GitCommandError",
     "evalue": "Cmd('git') failed due to: exit code(1)\n  cmdline: git pull -v -- origin",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGitCommandError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChecking for updates : Pulling the repository\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m repo \u001B[38;5;241m=\u001B[39m git\u001B[38;5;241m.\u001B[39mRepo(hive_git_repo_dir)\n\u001B[1;32m---> 21\u001B[0m \u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremotes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpull\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepository up to date\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\remote.py:1123\u001B[0m, in \u001B[0;36mRemote.pull\u001B[1;34m(self, refspec, progress, kill_after_timeout, allow_unsafe_protocols, allow_unsafe_options, **kwargs)\u001B[0m\n\u001B[0;32m   1118\u001B[0m     Git\u001B[38;5;241m.\u001B[39mcheck_unsafe_options(options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys()), unsafe_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munsafe_git_pull_options)\n\u001B[0;32m   1120\u001B[0m proc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mgit\u001B[38;5;241m.\u001B[39mpull(\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, refspec, with_stdout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, as_process\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, universal_newlines\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, v\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m   1122\u001B[0m )\n\u001B[1;32m-> 1123\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_fetch_info_from_stderr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkill_after_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_after_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39modb, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39modb\u001B[38;5;241m.\u001B[39mupdate_cache()\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\remote.py:895\u001B[0m, in \u001B[0;36mRemote._get_fetch_info_from_stderr\u001B[1;34m(self, proc, progress, kill_after_timeout)\u001B[0m\n\u001B[0;32m    885\u001B[0m handle_process_output(\n\u001B[0;32m    886\u001B[0m     proc,\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    891\u001B[0m     kill_after_timeout\u001B[38;5;241m=\u001B[39mkill_after_timeout,\n\u001B[0;32m    892\u001B[0m )\n\u001B[0;32m    894\u001B[0m stderr_text \u001B[38;5;241m=\u001B[39m progress\u001B[38;5;241m.\u001B[39merror_lines \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(progress\u001B[38;5;241m.\u001B[39merror_lines) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 895\u001B[0m \u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstderr_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stderr_text:\n\u001B[0;32m    897\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError lines received while fetching: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, stderr_text)\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\cmd.py:834\u001B[0m, in \u001B[0;36mGit.AutoInterrupt.wait\u001B[1;34m(self, stderr)\u001B[0m\n\u001B[0;32m    832\u001B[0m     errstr \u001B[38;5;241m=\u001B[39m read_all_from_possibly_closed_stream(p_stderr)\n\u001B[0;32m    833\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoInterrupt wait stderr: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (errstr,))\n\u001B[1;32m--> 834\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GitCommandError(remove_password_if_present(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs), status, errstr)\n\u001B[0;32m    835\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status\n",
      "\u001B[1;31mGitCommandError\u001B[0m: Cmd('git') failed due to: exit code(1)\n  cmdline: git pull -v -- origin"
     ]
    }
   ],
   "source": [
    "b_clone: bool = hive_git_always_clone == \"Yes\"\n",
    "\n",
    "# Check if HiveGitDirectory exists\n",
    "if not os.path.exists(hive_git_dir):\n",
    "    os.makedirs(hive_git_dir)\n",
    "    b_clone = True\n",
    "\n",
    "# Check if HiveGitRepoName exists\n",
    "if not os.path.exists(hive_git_repo_dir):\n",
    "    b_clone = True\n",
    "    \n",
    "if b_clone:\n",
    "    print(\"Cloning the repository\")\n",
    "    git.Repo.clone_from(hive_git_url, hive_git_repo_dir)\n",
    "    print(\"Repository cloned\")\n",
    "else:\n",
    "    print(\"Repository already cloned\")\n",
    "    if hive_git_always_pull == \"Yes\":\n",
    "        try :\n",
    "            print(\"Checking for updates : Pulling the repository\")\n",
    "            repo = git.Repo(hive_git_repo_dir)\n",
    "            repo.remotes.origin.pull()\n",
    "            print(\"Repository up to date\")\n",
    "        except GitCommandError as GT: \n",
    "            print(GT) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3a307d3c0c753",
   "metadata": {},
   "source": [
    "### 2.2 - Extract commits\n",
    "#### 2.2.1 - Check configuration to run the section"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc72901f3e5b994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.269136600Z",
     "start_time": "2024-11-17T23:57:54.768699Z"
    }
   },
   "source": [
    "section        : str   = \"GENERAL\"\n",
    "required_keys  : [str] = [\"MaxThreads\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "section         : str   = \"GIT\"\n",
    "required_keys  : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\",\n",
    "    \"HiveGitUrl\",\n",
    "    \"HiveGitAlwaysClone\",\n",
    "    \"HiveGitAlwaysPull\",\n",
    "    \"CommitPattern\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory      : str               = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name      : str               = config[\"GIT\"][\"HiveGitRepoName\"]\n",
    "hive_git_url            : str               = config[\"GIT\"][\"HiveGitUrl\"]\n",
    "hive_git_always_clone   : str               = config[\"GIT\"][\"HiveGitAlwaysClone\"]\n",
    "hive_git_always_pull    : str               = config[\"GIT\"][\"HiveGitAlwaysPull\"]\n",
    "commit_pattern          : re.Pattern        = re.compile(config[\"GIT\"][\"CommitPattern\"])\n",
    "max_threads             : int               = int(config[\"GENERAL\"][\"MaxThreads\"])\n",
    "\n",
    "# Get the number of threads\n",
    "num_threads             : int               = min(max_threads, os.cpu_count())\n",
    "# Get the repository directory\n",
    "hive_git_repo_dir       : str               = os.path.join(hive_git_dir, hive_git_repo_name)\n",
    "# Load the repository in memory\n",
    "repo                    : git.Repo          = git.Repo(hive_git_repo_dir)\n",
    "# List to store the couples (issue, file, commit)\n",
    "all_couples             : [(str, str, str)] = []\n",
    "# Split the commits into chunks\n",
    "chunk_size              : int               = len(list(repo.iter_commits())) // num_threads\n",
    "# Get all commits and files\n",
    "all_commits             : [dict]            = [{} for _ in range(num_threads)]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hive_git_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m num_threads             : \u001B[38;5;28mint\u001B[39m               \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(max_threads, os\u001B[38;5;241m.\u001B[39mcpu_count())\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Get the repository directory\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m hive_git_repo_dir       : \u001B[38;5;28mstr\u001B[39m               \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mhive_git_dir\u001B[49m, hive_git_repo_name)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Load the repository in memory\u001B[39;00m\n\u001B[0;32m     30\u001B[0m repo                    : git\u001B[38;5;241m.\u001B[39mRepo          \u001B[38;5;241m=\u001B[39m git\u001B[38;5;241m.\u001B[39mRepo(hive_git_repo_dir)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'hive_git_dir' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "de2684d6ce0cacbd",
   "metadata": {},
   "source": [
    "#### 2.2.2 - Extract commits\n",
    "\n",
    "##### Function to extract commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce1095fccefb228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.269136600Z",
     "start_time": "2024-11-17T20:42:21.555073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to process a batch of commits\n",
    "def process_commits(commits):\n",
    "    # Load the repository in memory of the current thread\n",
    "    local_repo = git.Repo(hive_git_repo_dir) \n",
    "    \n",
    "    tuple_key_file_commit = []\n",
    "    for commit_id in commits:\n",
    "        for match in commits[commit_id]:\n",
    "            hive_key = f'HIVE-{match}'\n",
    "            if hive_key in ids:\n",
    "                for file in local_repo.commit(commit_id).stats.files:\n",
    "                    tuple_key_file_commit.append((hive_key, file, commit_id))\n",
    "    return tuple_key_file_commit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c4c695aa5d9a4",
   "metadata": {},
   "source": [
    "##### Prepare multithreading to extract commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6776967ba7dac15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.269136600Z",
     "start_time": "2024-11-17T20:42:22.001630Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, commit in enumerate(repo.iter_commits()):\n",
    "    matches = commit_pattern.findall(commit.message)\n",
    "    if matches:\n",
    "        all_commits[i // chunk_size][commit.hexsha] = matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4c1a373e89f5b",
   "metadata": {},
   "source": [
    "##### Extract commits using multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130373effbc78d63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.270146200Z",
     "start_time": "2024-11-17T20:42:22.807689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20493 couples found.\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(process_commits, chunk) for chunk in all_commits]\n",
    "    for future in as_completed(futures):\n",
    "        couples = future.result()\n",
    "        all_couples.extend(couples)\n",
    "\n",
    "print(f\"{len(all_couples)} couples found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2357af0aba8ea1",
   "metadata": {},
   "source": [
    "### 2.3 - Filter data\n",
    "#### 2.3.1 - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c794fd07dcf6972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.270146200Z",
     "start_time": "2024-11-17T20:42:34.389006Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_dataframe : pd.DataFrame = pd.DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97a16882c9c061",
   "metadata": {},
   "source": [
    "#### 2.3.2 - Keep specific languages only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c87cfabddcab5dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.270146200Z",
     "start_time": "2024-11-17T20:42:34.412498Z"
    }
   },
   "outputs": [],
   "source": [
    "section         : str   = \"GENERAL\"\n",
    "required_keys   : [str] = [\"Languages\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "# Languages without whitespaces\n",
    "languages                   : [str]         = config[section][\"Languages\"].split(\",\")\n",
    "languages                   : [str]         = [lang.strip() for lang in languages]\n",
    "commit_dataframe_filtered   : pd.DataFrame  = commit_dataframe[\n",
    "                                                commit_dataframe['File'].str.endswith(tuple(languages))\n",
    "                                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2bc65ad2e9d73",
   "metadata": {},
   "source": [
    "### 2.4 - Extract filter versions from git\n",
    "#### 2.4.1 - Extract versions "
   ]
  },
  {
   "cell_type": "code",
   "id": "14b04c2b987e7060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.270146200Z",
     "start_time": "2024-11-17T23:58:07.819618Z"
    }
   },
   "source": [
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\",\n",
    "    \"HiveGitUrl\",\n",
    "    \"ReleasesRegex\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory  : str           = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name  : str           = config[\"GIT\"][\"HiveGitRepoName\"]\n",
    "hive_git_url        : str           = config[\"GIT\"][\"HiveGitUrl\"]\n",
    "releases_regex      : [str]         = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "\n",
    "releases_regex      : [str]         = [regex.strip() for regex in releases_regex]\n",
    "release_regex       : [re.Pattern]  = [re.compile(regex) for regex in releases_regex]\n",
    "\n",
    "repo                : git.Repo      = git.Repo(hive_git_repo_dir)\n",
    "tags                                = repo.tags\n",
    "versions            : dict          = {}\n",
    "\n",
    "for tag in tags:\n",
    "    # Get the commit of the tag\n",
    "    commit = tag.commit\n",
    "    versions[tag.name] = commit"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "8495e8f36ec6e4be",
   "metadata": {},
   "source": [
    "#### 2.4.2 - Filter versions"
   ]
  },
  {
   "cell_type": "code",
   "id": "795bacdf5f22e7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:33:02.319238Z",
     "start_time": "2024-11-20T02:33:02.307104Z"
    }
   },
   "source": [
    "filtered_versions : dict = {}\n",
    "for version in versions:\n",
    "    for regex in release_regex:\n",
    "        if regex.match(version):\n",
    "            version_numbers = version.split(\"-\")[1]\n",
    "            filtered_versions[version_numbers] = versions[version]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'versions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m filtered_versions : \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m version \u001B[38;5;129;01min\u001B[39;00m \u001B[43mversions\u001B[49m:\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m regex \u001B[38;5;129;01min\u001B[39;00m release_regex:\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m regex\u001B[38;5;241m.\u001B[39mmatch(version):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'versions' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "9bdb5a076bcf1613",
   "metadata": {},
   "source": [
    "#### 2.4.3 - Dict : Sort version by date in descending order "
   ]
  },
  {
   "cell_type": "code",
   "id": "8e76cb5febbdcf71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:33:00.943184Z",
     "start_time": "2024-11-20T02:33:00.929108Z"
    }
   },
   "source": [
    "sorted_filtered_versions_date = dict(sorted(filtered_versions.items(), \n",
    "                                        key=lambda item: item[1].committed_datetime, \n",
    "                                        reverse=True))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_versions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sorted_filtered_versions_date \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28msorted\u001B[39m(\u001B[43mfiltered_versions\u001B[49m\u001B[38;5;241m.\u001B[39mitems(), \n\u001B[0;32m      2\u001B[0m                                         key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m item: item[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcommitted_datetime, \n\u001B[0;32m      3\u001B[0m                                         reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'filtered_versions' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.293976400Z",
     "start_time": "2024-11-17T23:58:27.318058Z"
    }
   },
   "cell_type": "code",
   "source": "len(sorted_filtered_versions_date)",
   "id": "83d94cb21858a1da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "43a6780352270941",
   "metadata": {},
   "source": [
    "## Part 3. - Understand analysis\n",
    "\n",
    "### 3.1 - Set up the configuration and understand project\n",
    "\n",
    "#### 3.1.1 - Check configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "980fde46eb35382a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.294984900Z",
     "start_time": "2024-11-17T20:42:34.733704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hive\\\\hive.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section         : str   = \"UNDERSTAND\"    \n",
    "required_keys   : [str] = [\n",
    "    \"UnderstandCommand\",\n",
    "    \"UnderstandProjectName\",\n",
    "    \"UnderstandMetricsFileName\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory              : str   = config['GIT'][\"HiveGitDirectory\"]\n",
    "hive_repo_name                  : str   = config['GIT'][\"HiveGitRepoName\"]\n",
    "understand_project_name         : str   = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "und                             : str   = config[\"UNDERSTAND\"][\"UnderstandCommand\"]\n",
    "understand_metrics_file_name    : str   = config[\"UNDERSTAND\"][\"UnderstandMetricsFileName\"]\n",
    "\n",
    "und_project_path                : str   = os.path.join(hive_git_directory, understand_project_name)\n",
    "und_metrics_path                : str   = os.path.join(hive_git_directory, understand_project_name[:-4:] + \".csv\")\n",
    "hive_git_repo_dir               : str   = os.path.join(hive_git_directory, hive_repo_name)\n",
    "\n",
    "repo                            : git.Repo = git.Repo(hive_git_repo_dir)\n",
    "und_metrics_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd941f8b40611a5",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.2 - Understand commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617884aeeeab318e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.294984900Z",
     "start_time": "2024-11-17T20:42:34.755724Z"
    }
   },
   "outputs": [],
   "source": [
    "und_create              : str = f\"{und} create -db {und_project_path} -languages Java c++\"\n",
    "und_purge               : str = f\"{und} purge -db {und_project_path}\"\n",
    "und_add                 : str = f\"{und} add {hive_git_repo_dir} -db {und_project_path}\"\n",
    "und_settings_metrics    : str = f\"{und} settings -metrics all -db {und_project_path}\"\n",
    "und_settings_output     : str = f\"{und} settings -metricsOutputFile  -db {und_metrics_path} {und_project_path}\"\n",
    "und_analyze             : str = f\"{und} analyze -db {und_project_path} -quiet\"\n",
    "und_analyze_changes     : str = f\"{und} analyze -db {und_project_path} -quiet -rescan -changed\"\n",
    "und_metrics             : str = f\"{und} metrics {und_project_path}\"\n",
    "\n",
    "def run_command(command : str):\n",
    "    command_args : [str] = command.split(\" \")\n",
    "    print(f\"Running command : \\n     {command}\")\n",
    "    process = Popen(command_args, stdout=PIPE, stderr=PIPE).communicate()[0]\n",
    "    print(process.decode(\"utf-8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83944d484fed7a5",
   "metadata": {},
   "source": [
    "#### 3.1.3 Create the Understand project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d72013eb5881a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.294984900Z",
     "start_time": "2024-11-17T20:42:34.778245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if hive directory exists\n",
    "if not os.path.exists(hive_git_directory):\n",
    "    raise ValueError(f\"The directory {hive_git_directory} does not exist\")\n",
    "\n",
    "# Check if the Understand project exists\n",
    "if not os.path.exists(und_project_path):\n",
    "    run_command(und_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b624c2fd51c1c6d",
   "metadata": {},
   "source": [
    "#### 3.1.4 - Purge the Understand project\n",
    "**WARNING** : This will delete all the data in the Understand project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ca1af64a068c9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.294984900Z",
     "start_time": "2024-11-17T20:42:34.799317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command : \n",
      "     und purge -db hive\\hive.und\n",
      "Database purged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_command(und_purge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2cc1812b35f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T02:06:58.294984900Z",
     "start_time": "2024-11-17T20:42:34.953792Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out commit :  3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Adding commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264 to the Understand project\n",
      "Running command : \n",
      "     und add hive\\hiveRepo -db hive\\hive.und\n",
      "Directory: C:/Users/moshi/Documents/projects/Informatique/ETS/MGL869/MGL869-Lab-Hive/hive/hiveRepo already exists in project. Setting new properties. \n",
      "Files added: 8076\n",
      "\n",
      "Analyzing commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Running command : \n",
      "     und analyze -db hive\\hive.und -quiet -rescan -changed\n",
      "\n",
      "Exporting metrics for commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Running command : \n",
      "     und metrics hive\\hive.und\n"
     ]
    }
   ],
   "source": [
    "for version in sorted_filtered_versions_date :\n",
    "    t = time()\n",
    "    commit = sorted_filtered_versions_date[version]\n",
    "    print(\"Checking out commit : \", commit)\n",
    "    repo.git.checkout(commit)\n",
    "    print(f\"Adding commit {commit} to the Understand project\")\n",
    "    run_command(und_add)\n",
    "    print(f\"Analyzing commit {commit}\")\n",
    "    run_command(und_analyze_changes)\n",
    "    print(f\"Exporting metrics for commit {commit}\")\n",
    "    run_command(und_metrics)\n",
    "    # Copy UnderstandProjectName.csv to the output directory and set file name as UnderstandMetricsFileName\n",
    "    shutil.copy(und_metrics_path, os.path.join(config[\"OUTPUT\"][\"OutputDir\"], understand_metrics_file_name + str(version)))\n",
    "    print(t-time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
