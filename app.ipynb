{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **LÃ©o FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ],
   "id": "60ba9198ea3046db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "5a37f0a23417b4ad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:24.590404Z",
     "start_time": "2024-11-17T05:22:20.710689Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import re\n",
    "import shutil\n",
    "from time import time\n",
    "import configparser\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from numpy.ma.testutils import assert_equal\n",
    "\n",
    "from hiveDL import hiveDL"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:24.599842Z",
     "start_time": "2024-11-17T05:22:24.594004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "required_sections = [\"GENERAL\", \"GIT\", \"JIRA\", \"UNDERSTAND\", \"OUTPUT\", \"JUPYTER\"]\n",
    "for section in required_sections:\n",
    "    assert section in config, f\"Section {section} is missing in the configuration file\""
   ],
   "id": "f397c103fa890c48",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:25.371042Z",
     "start_time": "2024-11-17T05:22:25.367178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def testConfig(section, keys):\n",
    "    assert section in config, f\"Section {section} is missing in the configuration file\"\n",
    "    for key in requiered_keys:\n",
    "        assert key in config[section], f\"Key {key} is missing in the configuration file\"\n",
    "        assert config[section][key], f\"Key {key} is empty in the configuration file\""
   ],
   "id": "a43a03e34f82b596",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 1 : Data collection\n",
    "\n",
    "### 1.1 - Download Jira data\n",
    "\n",
    "#### 1.1.1 - Check configuration to run the section"
   ],
   "id": "df29392ee535edd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:25.382095Z",
     "start_time": "2024-11-17T05:22:25.378315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"JIRA\"\n",
    "requiered_keys = [\"BaseUrl\", \"SearchComplement\", \"Query\", \"JiraCSVDirectory\", \"QueryEachRun\", \"JiraCombinedCSV\"]\n",
    "\n",
    "testConfig(section, requiered_keys)"
   ],
   "id": "8494cabba75ef4b9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1.2 - Download Jira data if needed",
   "id": "2769a039af9231ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:25.396680Z",
     "start_time": "2024-11-17T05:22:25.389291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if we need to download the data each time\n",
    "data_exists = config[section][\"QueryEachRun\"] == \"No\"\n",
    "\n",
    "# Check if the directory exists\n",
    "jira_csv_dir = config[section][\"JiraCSVDirectory\"]\n",
    "if not os.path.exists(jira_csv_dir):\n",
    "    data_exists = False\n",
    "    os.makedirs(jira_csv_dir)\n",
    "\n",
    "# Check if there is a command.txt file in the directory\n",
    "command_file = os.path.join(jira_csv_dir, \"command.txt\")\n",
    "if not os.path.exists(command_file):\n",
    "    data_exists = False\n",
    "else:\n",
    "    with open(command_file, \"r\") as f:\n",
    "        query = f.read()\n",
    "\n",
    "    if query != config[section][\"Query\"]:\n",
    "        data_exists = False\n",
    "\n",
    "# Check if at least one .csv file exists in the directory\n",
    "csv_files = [f for f in os.listdir(jira_csv_dir) if f.endswith(\".csv\")]\n",
    "if not csv_files:\n",
    "    data_exists = False\n",
    "\n",
    "combined_csv_path = os.path.join(jira_csv_dir, config[section][\"JiraCombinedCSV\"])\n",
    "\n",
    "if not data_exists:\n",
    "    print(\"Downloading Jira data with pagination\")\n",
    "    base_url = config[section][\"BaseUrl\"]\n",
    "    search_complement = config[section][\"SearchComplement\"]\n",
    "    query = config[section][\"Query\"]\n",
    "    jira_csv_dir = config[section][\"JiraCSVDirectory\"]\n",
    "    temp_max = 1000\n",
    "    start = 0\n",
    "\n",
    "    \n",
    "    try:\n",
    "        hiveDL(\n",
    "            command_file,\n",
    "            jira_csv_dir,\n",
    "            combined_csv_path,\n",
    "            base_url,\n",
    "            search_complement,\n",
    "            query,\n",
    "            temp_max = temp_max,\n",
    "            start = start\n",
    "        )\n",
    "\n",
    "        \n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"Error during data fetching: {err}\")\n",
    "        raise SystemExit(err)\n",
    "else:\n",
    "    print(\"Data already exists\")"
   ],
   "id": "becddda604c83392",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "#### 1.2.1 - Load the data"
   ],
   "id": "c9217dbe844954a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:25.850472Z",
     "start_time": "2024-11-17T05:22:25.410813Z"
    }
   },
   "cell_type": "code",
   "source": "jira_dataframe = pd.read_csv(combined_csv_path, low_memory=False)",
   "id": "d1cce1ee9c75dd1c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2.2 - Keep only the relevant columns",
   "id": "57888f3c459618f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:25.873186Z",
     "start_time": "2024-11-17T05:22:25.869899Z"
    }
   },
   "cell_type": "code",
   "source": "keep: list = ['Issue key', 'Status', 'Resolution', 'Created', 'Fix Versions Combined', 'Affects Versions Combined']",
   "id": "80eda3f2af2c0baa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:26.208455Z",
     "start_time": "2024-11-17T05:22:25.883332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "affects_version_columns = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "\n",
    "fix_version_columns = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "# Combine the versions into a single column\n",
    "jira_dataframe['Fix Versions Combined'] = jira_dataframe[fix_version_columns].apply(lambda x: ', '.join(x.dropna().astype(str)), axis=1)\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(lambda x: ', '.join(x.dropna().astype(str)),  axis=1)\n",
    "\n",
    "jira_dataframe = jira_dataframe.loc[:, keep]"
   ],
   "id": "885c979912c66a4d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2.3 - Extract ids",
   "id": "79d1219c2c4a5a11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:26.223120Z",
     "start_time": "2024-11-17T05:22:26.217969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "unique_issue_keys = set(flattened_issue_keys)\n",
    "# The result is a set of unique 'Issue key' values\n",
    "ids = unique_issue_keys"
   ],
   "id": "156b007c777f1b43",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 2 : Repository analysis\n",
    "### 2.1 - Clone repository\n",
    "#### 2.1.1 - Check configuration to run the section"
   ],
   "id": "92aa5b6235cb5d2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:26.238362Z",
     "start_time": "2024-11-17T05:22:26.235398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"GIT\"\n",
    "requiered_keys = [\"HiveGitDirectory\", \"HiveGitRepoName\", \"HiveGitUrl\", \"HiveGitAlwaysClone\", \"HiveGitAlwaysPull\"]\n",
    "\n",
    "testConfig(section, requiered_keys)"
   ],
   "id": "9d4b6784645fa299",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1.2 - Clone repository if needed",
   "id": "6ec30dd565ce4f18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:26.790143Z",
     "start_time": "2024-11-17T05:22:26.249004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b_clone: bool = config[section][\"HiveGitAlwaysClone\"] == \"Yes\"\n",
    "\n",
    "# Check if HiveGitDirectory exists\n",
    "hive_git_dir = config[section][\"HiveGitDirectory\"]\n",
    "if not os.path.exists(hive_git_dir):\n",
    "    os.makedirs(hive_git_dir)\n",
    "    b_clone = True\n",
    "\n",
    "# Check if HiveGitRepoName exists\n",
    "hive_git_url = config[section][\"HiveGitUrl\"]\n",
    "hive_git_repo_name = config[section][\"HiveGitRepoName\"]\n",
    "hive_git_repo_dir = os.path.join(hive_git_dir, hive_git_repo_name)\n",
    "if not os.path.exists(hive_git_repo_dir):\n",
    "    b_clone = True\n",
    "    \n",
    "if b_clone:\n",
    "    print(\"Cloning the repository\")\n",
    "    git.Repo.clone_from(hive_git_url, hive_git_repo_dir)\n",
    "    print(\"Repository cloned\")\n",
    "else:\n",
    "    print(\"Repository already cloned\")\n",
    "    if config[section][\"HiveGitAlwaysPull\"] == \"Yes\":\n",
    "        print(\"Checking for updates : Pulling the repository\")\n",
    "        repo = git.Repo(hive_git_repo_dir)\n",
    "        repo.remotes.origin.pull()\n",
    "        print(\"Repository up to date\")\n",
    "        "
   ],
   "id": "d9eb30c27ad733a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already cloned\n",
      "Checking for updates : Pulling the repository\n",
      "Repository up to date\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 - Extract commits\n",
    "#### 2.2.1 - Check configuration to run the section"
   ],
   "id": "6cc3a307d3c0c753"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:27.028227Z",
     "start_time": "2024-11-17T05:22:26.815628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"GENERAL\"\n",
    "requiered_keys = [\"MaxThreads\"]\n",
    "\n",
    "testConfig(section, requiered_keys)\n",
    "\n",
    "section = \"GIT\"\n",
    "requiered_keys = [\"HiveGitDirectory\", \"HiveGitRepoName\", \"HiveGitUrl\", \"HiveGitAlwaysClone\", \"HiveGitAlwaysPull\", \"CommitPattern\"]\n",
    "\n",
    "testConfig(section, requiered_keys)\n",
    "\n",
    "# Get the commit pattern\n",
    "pattern = re.compile(config[\"GIT\"][\"CommitPattern\"])\n",
    "# Get the number of threads\n",
    "num_threads = min(int(config[\"GENERAL\"][\"MaxThreads\"]), os.cpu_count())\n",
    "# Get the repository directory\n",
    "hive_git_repo_dir = os.path.join(hive_git_dir, hive_git_repo_name)\n",
    "# Load the repository in memory\n",
    "repo = git.Repo(hive_git_repo_dir)\n",
    "# List to store the couples (issue, file, commit)\n",
    "all_couples = []\n",
    "# Split the commits into chunks\n",
    "chunk_size = len(list(repo.iter_commits())) // num_threads\n",
    "# Get all commits and files\n",
    "all_commits = [{} for _ in range(num_threads)]"
   ],
   "id": "dc72901f3e5b994",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 - Extract commits\n",
    "\n",
    "##### Function to extract commits"
   ],
   "id": "de2684d6ce0cacbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:27.051605Z",
     "start_time": "2024-11-17T05:22:27.046254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to process a batch of commits\n",
    "def process_commits(commits):\n",
    "    local_repo = git.Repo(hive_git_repo_dir) # Load the repository in memory of the current thread\n",
    "    tuple_key_file_commit = []\n",
    "    for commit_id in commits:\n",
    "        for match in commits[commit_id]:\n",
    "            hive_key = f'HIVE-{match}'\n",
    "            if hive_key in ids:\n",
    "                for file in local_repo.commit(commit_id).stats.files:\n",
    "                    tuple_key_file_commit.append((hive_key, file, commit_id))\n",
    "    return tuple_key_file_commit"
   ],
   "id": "bce1095fccefb228",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Prepare multithreading to extract commits",
   "id": "4a3c4c695aa5d9a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:28.007650Z",
     "start_time": "2024-11-17T05:22:27.093966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, commit in enumerate(repo.iter_commits()):\n",
    "    matches = pattern.findall(commit.message)\n",
    "    if matches:\n",
    "        all_commits[i // chunk_size][commit.hexsha] = matches"
   ],
   "id": "a6776967ba7dac15",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Extract commits using multithreading",
   "id": "d7a4c1a373e89f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.409508Z",
     "start_time": "2024-11-17T05:22:28.016440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(process_commits, chunk) for chunk in all_commits]\n",
    "    for future in as_completed(futures):\n",
    "        couples = future.result()\n",
    "        all_couples.extend(couples)\n",
    "\n",
    "print(f\"{len(all_couples)} couples found.\")"
   ],
   "id": "130373effbc78d63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20524 couples found.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 - Filter data\n",
    "#### 2.3.1 - Create a DataFrame"
   ],
   "id": "2f2357af0aba8ea1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.504031Z",
     "start_time": "2024-11-17T05:22:46.495145Z"
    }
   },
   "cell_type": "code",
   "source": "commit_dataframe = pd.DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])",
   "id": "5c794fd07dcf6972",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3.2 - Keep specific languages only",
   "id": "4a97a16882c9c061"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.541085Z",
     "start_time": "2024-11-17T05:22:46.530846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"GENERAL\"\n",
    "requiered_keys = [\"Languages\"]\n",
    "\n",
    "testConfig(section, requiered_keys)\n",
    "\n",
    "languages = config[section][\"Languages\"].split(\",\")\n",
    "# Remove potential whitespaces\n",
    "languages = [lang.strip() for lang in languages]\n",
    "\n",
    "commit_dataframe_filtered = commit_dataframe[commit_dataframe['File'].str.endswith(tuple(languages))]"
   ],
   "id": "5c87cfabddcab5dd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.4 - Extract filter versions from git\n",
    "#### 2.4.1 - Extract versions "
   ],
   "id": "f7c2bc65ad2e9d73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.740564Z",
     "start_time": "2024-11-17T05:22:46.544948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"GIT\"\n",
    "requiered_keys = [\"HiveGitDirectory\", \"HiveGitRepoName\", \"HiveGitUrl\",  \"ReleasesRegex\"]\n",
    "\n",
    "testConfig(section, requiered_keys)\n",
    "\n",
    "repo = git.Repo(hive_git_repo_dir)\n",
    "tags = repo.tags\n",
    "versions = {}\n",
    "\n",
    "for tag in tags:\n",
    "    # Get the commit of the tag\n",
    "    commit = tag.commit\n",
    "    versions[tag.name] = commit"
   ],
   "id": "14b04c2b987e7060",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.4.2 - Filter versions",
   "id": "8495e8f36ec6e4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.758164Z",
     "start_time": "2024-11-17T05:22:46.753852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_versions = {}\n",
    "releases_regex = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "releases_regex = [regex.strip() for regex in releases_regex]\n",
    "release_regex = [re.compile(regex) for regex in releases_regex]\n",
    "\n",
    "for version in versions:\n",
    "    for regex in release_regex:\n",
    "        if regex.match(version):\n",
    "            version_numbers = version.split(\"-\")[1]\n",
    "            filtered_versions[version_numbers] = versions[version]"
   ],
   "id": "795bacdf5f22e7c0",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.4.3 - Dict : Sort version by date in descending order ",
   "id": "9bdb5a076bcf1613"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:46.778259Z",
     "start_time": "2024-11-17T05:22:46.770821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sorted_filtered_versions_date = dict(sorted(filtered_versions.items(), \n",
    "                                        key=lambda item: item[1].committed_datetime, \n",
    "                                        reverse=True))"
   ],
   "id": "8e76cb5febbdcf71",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 3. - Understand analysis\n",
    "\n",
    "### 3.1 - Set up the configuration and understand project\n",
    "\n",
    "#### 3.1.1 - Check configuration"
   ],
   "id": "43a6780352270941"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T05:22:47.149023Z",
     "start_time": "2024-11-17T05:22:46.792172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "section = \"UNDERSTAND\"    \n",
    "requiered_keys = [\"UnderstandCommand\", \"UnderstandProjectName\", \"UnderstandMetricsFileName\"]\n",
    "\n",
    "testConfig(section, requiered_keys)\n",
    "\n",
    "section = \"GIT\"\n",
    "required_sections = [\"HiveGitDirectory\", \"GiveGitRepoName\"]\n",
    "\n",
    "testConfig(section, required_sections)"
   ],
   "id": "980fde46eb35382a",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Key UnderstandCommand is missing in the configuration file",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m section \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGIT\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      7\u001B[0m required_sections \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHiveGitDirectory\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGiveGitRepoName\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtestConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43msection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequired_sections\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 4\u001B[0m, in \u001B[0;36mtestConfig\u001B[1;34m(section, keys)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m section \u001B[38;5;129;01min\u001B[39;00m config, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSection \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msection\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is missing in the configuration file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m requiered_keys:\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m config[section], \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is missing in the configuration file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m config[section][key], \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is empty in the configuration file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mAssertionError\u001B[0m: Key UnderstandCommand is missing in the configuration file"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 3.1.2 - Understand commands"
   ],
   "id": "1cd941f8b40611a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hive_git_directory = config['GIT'][\"HiveGitDirectory\"]\n",
    "hive_repo_name = config['GIT'][\"HiveGitRepoName\"]\n",
    "understand_project_name = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "und = config[\"UNDERSTAND\"][\"UnderstandCommand\"]\n",
    "understand_metrics_file_name = config[\"UNDERSTAND\"][\"UnderstandMetricsFileName\"]\n",
    "\n",
    "und_project_path = os.path.join(hive_git_directory, understand_project_name)\n",
    "und_metrics_path = os.path.join(hive_git_directory, understand_metrics_file_name)\n",
    "hive_git_repo_dir = os.path.join(hive_git_directory, hive_repo_name)\n",
    "\n",
    "und_create = f\"{und} create -db {und_project_path} -languages Java c++\"\n",
    "und_purge = f\"{und} purge -db {und_project_path}\"\n",
    "und_add = f\"{und} add {hive_git_repo_dir} -db {und_project_path}\"\n",
    "und_settings_metrics = f\"{und} settings -metrics all -db {und_project_path}\"\n",
    "und_settings_output = f\"{und} settings -metricsOutputFile  -db {und_metrics_path} {und_project_path}\"\n",
    "und_analyze = f\"{und} analyze -db {und_project_path} -quiet\""
   ],
   "id": "617884aeeeab318e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.1.3 Create the Understand project",
   "id": "83944d484fed7a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if hive directory exists\n",
    "hive_directory = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "if not os.path.exists(hive_directory):\n",
    "    raise ValueError(f\"The directory {hive_directory} does not exist\")\n",
    "\n",
    "# Check if the understand project exists\n",
    "understand_project_name = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "understand_project_path = os.path.join(hive_directory, understand_project_name)\n",
    "if not os.path.exists(understand_project_path):\n",
    "    print(\"Creating the Understand project\")\n",
    "    subprocess.run(und_create, check=True)\n",
    "    print(\"Understand project created\")"
   ],
   "id": "8d72013eb5881a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.1.4 - Purge the Understand project\n",
    "**WARNING** : This will delete all the data in the Understand project"
   ],
   "id": "4b624c2fd51c1c6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Purging the Understand project\")\n",
    "subprocess.run(und_purge, check=True)\n",
    "print(\"Understand project purged\")"
   ],
   "id": "8ca1af64a068c9e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Adding settings to the Understand project\")\n",
    "subprocess.run(und_settings_metrics, check=True)\n",
    "subprocess.run(und_settings_output, check=True)\n",
    "print(\"Settings added\")"
   ],
   "id": "26dd5d64f4bdba91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Adding the repository to the Understand project\")\n",
    "subprocess.run(und_add, check=True)\n",
    "print(\"Repository added\")"
   ],
   "id": "990e1a72419f6cd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Analyzing the repository\")\n",
    "subprocess.run(und_analyze, check=True)\n",
    "print(\"Repository analyzed\")"
   ],
   "id": "5b62c5ad75d6099e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ef3f5c85e4b5904c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
