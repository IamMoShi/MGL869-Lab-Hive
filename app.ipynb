{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ba9198ea3046db",
   "metadata": {},
   "source": [
    "# MGL869 - Lab\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **LÃ©o FORNOFF**\n",
    "- **William PHAN**\n",
    "- **Yannis OUAKRIM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37f0a23417b4ad",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:57:21.796976Z",
     "start_time": "2024-11-17T23:57:19.835917Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import git\n",
    "import re\n",
    "import shutil\n",
    "import configparser\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "from hiveDL import hiveDL"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f397c103fa890c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:57:21.827669Z",
     "start_time": "2024-11-17T23:57:21.813988Z"
    }
   },
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "required_sections : [str] = [\n",
    "    \"GENERAL\",\n",
    "    \"GIT\",\n",
    "    \"JIRA\",\n",
    "    \"UNDERSTAND\",\n",
    "    \"OUTPUT\",\n",
    "    \"JUPYTER\"]\n",
    "\n",
    "for section in required_sections:\n",
    "    assert section in config, f\"Section {section} is missing in the configuration file\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a43a03e34f82b596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:57:38.853039Z",
     "start_time": "2024-11-17T23:57:38.848917Z"
    }
   },
   "source": [
    "def testConfig(t_section: str, keys : [str]):\n",
    "    assert t_section in config          , f\"Section {t_section} is missing in the configuration file\"\n",
    "    for key in keys:\n",
    "        assert key in config[t_section] , f\"Key {key} is missing in the configuration file\"\n",
    "        assert config[t_section][key]   , f\"Key {key} is empty in the configuration file\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "df29392ee535edd8",
   "metadata": {},
   "source": [
    "## Part 1 : Data collection\n",
    "\n",
    "### 1.1 - Download Jira data\n",
    "\n",
    "#### 1.1.1 - Check configuration to run the section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8494cabba75ef4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:08.713204Z",
     "start_time": "2024-11-17T20:42:08.707560Z"
    }
   },
   "outputs": [],
   "source": [
    "section         : str   = \"JIRA\"\n",
    "required_keys   : [str] = [\n",
    "    \"BaseUrl\",\n",
    "    \"SearchComplement\",\n",
    "    \"Query\",\n",
    "    \"JiraCSVDirectory\",\n",
    "    \"QueryEachRun\",\n",
    "    \"JiraCombinedCSV\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "base_url            : str   = config[section][\"BaseUrl\"]\n",
    "search_complement   : str   = config[section][\"SearchComplement\"]\n",
    "query               : str   = config[section][\"Query\"]\n",
    "jira_csv_directory  : str   = config[section][\"JiraCSVDirectory\"]\n",
    "query_each_run      : str   = config[section][\"QueryEachRun\"]\n",
    "jira_combined_csv   : str   = config[section][\"JiraCombinedCSV\"]\n",
    "\n",
    "command_file                = os.path.join(jira_csv_directory, \"command.txt\")\n",
    "combined_csv_path           = os.path.join(jira_csv_directory, jira_combined_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769a039af9231ce",
   "metadata": {},
   "source": [
    "#### 1.1.2 - Download Jira data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becddda604c83392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:08.734681Z",
     "start_time": "2024-11-17T20:42:08.720534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists\n"
     ]
    }
   ],
   "source": [
    "# Check if we need to download the data each time\n",
    "data_exists : bool  = query_each_run == \"No\"\n",
    "# Check if at least one .csv file exists in the directory\n",
    "csv_files   : [str] = [f for f in os.listdir(jira_csv_directory) if f.endswith(\".csv\")]\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(jira_csv_directory):\n",
    "    os.makedirs(jira_csv_directory)\n",
    "    data_exists = False\n",
    "    \n",
    "# Check if there is a command.txt file in the directory\n",
    "if not os.path.exists(command_file):\n",
    "    data_exists = False\n",
    "else:\n",
    "    with open(command_file, \"r\") as f:\n",
    "        if f.read() != query:\n",
    "            data_exists = False\n",
    "        \n",
    "data_exists = data_exists and len(csv_files) > 0\n",
    "\n",
    "if not data_exists:\n",
    "    temp_max    : int   = 1000\n",
    "    start       : int   = 0\n",
    "    try:\n",
    "        print(\"Downloading Jira data with pagination\")\n",
    "        hiveDL(\n",
    "            command_file,\n",
    "            jira_csv_directory,\n",
    "            combined_csv_path,\n",
    "            base_url,\n",
    "            search_complement,\n",
    "            query,\n",
    "            temp_max = temp_max,\n",
    "            start = start\n",
    "        )\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"Error during data fetching: {err}\")\n",
    "        raise SystemExit(err)\n",
    "else:\n",
    "    print(\"Data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9217dbe844954a3",
   "metadata": {},
   "source": [
    "### 1.2 - Clean Jira data using pandas\n",
    "#### 1.2.1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1cce1ee9c75dd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:09.415030Z",
     "start_time": "2024-11-17T20:42:08.784172Z"
    }
   },
   "outputs": [],
   "source": [
    "jira_dataframe = pd.read_csv(combined_csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57888f3c459618f9",
   "metadata": {},
   "source": [
    "#### 1.2.2 - Keep only the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80eda3f2af2c0baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:09.423071Z",
     "start_time": "2024-11-17T20:42:09.419045Z"
    }
   },
   "outputs": [],
   "source": [
    "keep: [str] = [\n",
    "    'Issue key',\n",
    "    'Status', \n",
    "    'Resolution', \n",
    "    'Created', \n",
    "    'Fix Versions Combined', \n",
    "    'Affects Versions Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885c979912c66a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:09.785877Z",
     "start_time": "2024-11-17T20:42:09.452710Z"
    }
   },
   "outputs": [],
   "source": [
    "affects_version_columns : [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "fix_version_columns     : [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "# Combine the versions into a single column\n",
    "jira_dataframe['Fix Versions Combined']     = jira_dataframe[fix_version_columns].apply(\n",
    "                                                    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    "                                                )\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "                                                    lambda x: ', '.join(x.dropna().astype(str)),  axis=1\n",
    "                                                )\n",
    "\n",
    "jira_dataframe                              = jira_dataframe.loc[:, keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1219c2c4a5a11",
   "metadata": {},
   "source": [
    "#### 1.2.3 - Extract ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156b007c777f1b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:09.803117Z",
     "start_time": "2024-11-17T20:42:09.795319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Issue key'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns       : pd.Index      = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values        : np.ndarray    = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys    : np.ndarray    = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "unique_issue_keys       : set           = set(flattened_issue_keys)\n",
    "# The result is a set of unique 'Issue key' values\n",
    "ids                     : set           = unique_issue_keys\n",
    "\n",
    "issue_key_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa5b6235cb5d2d",
   "metadata": {},
   "source": [
    "## Part 2 : Repository analysis\n",
    "### 2.1 - Clone repository\n",
    "#### 2.1.1 - Check configuration to run the section"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d4b6784645fa299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:58:02.162618Z",
     "start_time": "2024-11-17T23:58:02.158457Z"
    }
   },
   "source": [
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\", \n",
    "    \"HiveGitUrl\", \n",
    "    \"HiveGitAlwaysClone\", \n",
    "    \"HiveGitAlwaysPull\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_dir            : str   = config[section][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name      : str   = config[section][\"HiveGitRepoName\"]\n",
    "hive_git_url            : str   = config[section][\"HiveGitUrl\"]\n",
    "hive_git_always_clone   : str   = config[section][\"HiveGitAlwaysClone\"]\n",
    "hive_git_always_pull    : str   = config[section][\"HiveGitAlwaysPull\"]\n",
    "\n",
    "hive_git_repo_dir       : str   = os.path.join(hive_git_dir, hive_git_repo_name)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "6ec30dd565ce4f18",
   "metadata": {},
   "source": [
    "#### 2.1.2 - Clone repository if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9eb30c27ad733a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:10.887748Z",
     "start_time": "2024-11-17T20:42:09.860379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already cloned\n",
      "Checking for updates : Pulling the repository\n"
     ]
    },
    {
     "ename": "GitCommandError",
     "evalue": "Cmd('git') failed due to: exit code(1)\n  cmdline: git pull -v -- origin",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGitCommandError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChecking for updates : Pulling the repository\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m repo \u001B[38;5;241m=\u001B[39m git\u001B[38;5;241m.\u001B[39mRepo(hive_git_repo_dir)\n\u001B[1;32m---> 21\u001B[0m \u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremotes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpull\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepository up to date\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\remote.py:1123\u001B[0m, in \u001B[0;36mRemote.pull\u001B[1;34m(self, refspec, progress, kill_after_timeout, allow_unsafe_protocols, allow_unsafe_options, **kwargs)\u001B[0m\n\u001B[0;32m   1118\u001B[0m     Git\u001B[38;5;241m.\u001B[39mcheck_unsafe_options(options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys()), unsafe_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munsafe_git_pull_options)\n\u001B[0;32m   1120\u001B[0m proc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39mgit\u001B[38;5;241m.\u001B[39mpull(\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, refspec, with_stdout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, as_process\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, universal_newlines\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, v\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m   1122\u001B[0m )\n\u001B[1;32m-> 1123\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_fetch_info_from_stderr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkill_after_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_after_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39modb, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo\u001B[38;5;241m.\u001B[39modb\u001B[38;5;241m.\u001B[39mupdate_cache()\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\remote.py:895\u001B[0m, in \u001B[0;36mRemote._get_fetch_info_from_stderr\u001B[1;34m(self, proc, progress, kill_after_timeout)\u001B[0m\n\u001B[0;32m    885\u001B[0m handle_process_output(\n\u001B[0;32m    886\u001B[0m     proc,\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    891\u001B[0m     kill_after_timeout\u001B[38;5;241m=\u001B[39mkill_after_timeout,\n\u001B[0;32m    892\u001B[0m )\n\u001B[0;32m    894\u001B[0m stderr_text \u001B[38;5;241m=\u001B[39m progress\u001B[38;5;241m.\u001B[39merror_lines \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(progress\u001B[38;5;241m.\u001B[39merror_lines) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 895\u001B[0m \u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstderr_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stderr_text:\n\u001B[0;32m    897\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError lines received while fetching: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, stderr_text)\n",
      "File \u001B[1;32m~\\Documents\\projects\\Informatique\\ETS\\MGL869\\MGL869-Lab-Hive\\.venv\\Lib\\site-packages\\git\\cmd.py:834\u001B[0m, in \u001B[0;36mGit.AutoInterrupt.wait\u001B[1;34m(self, stderr)\u001B[0m\n\u001B[0;32m    832\u001B[0m     errstr \u001B[38;5;241m=\u001B[39m read_all_from_possibly_closed_stream(p_stderr)\n\u001B[0;32m    833\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoInterrupt wait stderr: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (errstr,))\n\u001B[1;32m--> 834\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GitCommandError(remove_password_if_present(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs), status, errstr)\n\u001B[0;32m    835\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status\n",
      "\u001B[1;31mGitCommandError\u001B[0m: Cmd('git') failed due to: exit code(1)\n  cmdline: git pull -v -- origin"
     ]
    }
   ],
   "source": [
    "b_clone: bool = hive_git_always_clone == \"Yes\"\n",
    "\n",
    "# Check if HiveGitDirectory exists\n",
    "if not os.path.exists(hive_git_dir):\n",
    "    os.makedirs(hive_git_dir)\n",
    "    b_clone = True\n",
    "\n",
    "# Check if HiveGitRepoName exists\n",
    "if not os.path.exists(hive_git_repo_dir):\n",
    "    b_clone = True\n",
    "    \n",
    "if b_clone:\n",
    "    print(\"Cloning the repository\")\n",
    "    git.Repo.clone_from(hive_git_url, hive_git_repo_dir)\n",
    "    print(\"Repository cloned\")\n",
    "else:\n",
    "    print(\"Repository already cloned\")\n",
    "    if hive_git_always_pull == \"Yes\":\n",
    "        try :\n",
    "            print(\"Checking for updates : Pulling the repository\")\n",
    "            repo = git.Repo(hive_git_repo_dir)\n",
    "            repo.remotes.origin.pull()\n",
    "            print(\"Repository up to date\")\n",
    "        except GitCommandError as GT: \n",
    "            print(GT) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3a307d3c0c753",
   "metadata": {},
   "source": [
    "### 2.2 - Extract commits\n",
    "#### 2.2.1 - Check configuration to run the section"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc72901f3e5b994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:57:54.789451Z",
     "start_time": "2024-11-17T23:57:54.768699Z"
    }
   },
   "source": [
    "section        : str   = \"GENERAL\"\n",
    "required_keys  : [str] = [\"MaxThreads\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "section         : str   = \"GIT\"\n",
    "required_keys  : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\",\n",
    "    \"HiveGitUrl\",\n",
    "    \"HiveGitAlwaysClone\",\n",
    "    \"HiveGitAlwaysPull\",\n",
    "    \"CommitPattern\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory      : str               = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name      : str               = config[\"GIT\"][\"HiveGitRepoName\"]\n",
    "hive_git_url            : str               = config[\"GIT\"][\"HiveGitUrl\"]\n",
    "hive_git_always_clone   : str               = config[\"GIT\"][\"HiveGitAlwaysClone\"]\n",
    "hive_git_always_pull    : str               = config[\"GIT\"][\"HiveGitAlwaysPull\"]\n",
    "commit_pattern          : re.Pattern        = re.compile(config[\"GIT\"][\"CommitPattern\"])\n",
    "max_threads             : int               = int(config[\"GENERAL\"][\"MaxThreads\"])\n",
    "\n",
    "# Get the number of threads\n",
    "num_threads             : int               = min(max_threads, os.cpu_count())\n",
    "# Get the repository directory\n",
    "hive_git_repo_dir       : str               = os.path.join(hive_git_dir, hive_git_repo_name)\n",
    "# Load the repository in memory\n",
    "repo                    : git.Repo          = git.Repo(hive_git_repo_dir)\n",
    "# List to store the couples (issue, file, commit)\n",
    "all_couples             : [(str, str, str)] = []\n",
    "# Split the commits into chunks\n",
    "chunk_size              : int               = len(list(repo.iter_commits())) // num_threads\n",
    "# Get all commits and files\n",
    "all_commits             : [dict]            = [{} for _ in range(num_threads)]"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hive_git_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m num_threads             : \u001B[38;5;28mint\u001B[39m               \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(max_threads, os\u001B[38;5;241m.\u001B[39mcpu_count())\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Get the repository directory\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m hive_git_repo_dir       : \u001B[38;5;28mstr\u001B[39m               \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mhive_git_dir\u001B[49m, hive_git_repo_name)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Load the repository in memory\u001B[39;00m\n\u001B[0;32m     30\u001B[0m repo                    : git\u001B[38;5;241m.\u001B[39mRepo          \u001B[38;5;241m=\u001B[39m git\u001B[38;5;241m.\u001B[39mRepo(hive_git_repo_dir)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'hive_git_dir' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "de2684d6ce0cacbd",
   "metadata": {},
   "source": [
    "#### 2.2.2 - Extract commits\n",
    "\n",
    "##### Function to extract commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bce1095fccefb228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:21.559897Z",
     "start_time": "2024-11-17T20:42:21.555073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to process a batch of commits\n",
    "def process_commits(commits):\n",
    "    # Load the repository in memory of the current thread\n",
    "    local_repo = git.Repo(hive_git_repo_dir) \n",
    "    \n",
    "    tuple_key_file_commit = []\n",
    "    for commit_id in commits:\n",
    "        for match in commits[commit_id]:\n",
    "            hive_key = f'HIVE-{match}'\n",
    "            if hive_key in ids:\n",
    "                for file in local_repo.commit(commit_id).stats.files:\n",
    "                    tuple_key_file_commit.append((hive_key, file, commit_id))\n",
    "    return tuple_key_file_commit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c4c695aa5d9a4",
   "metadata": {},
   "source": [
    "##### Prepare multithreading to extract commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6776967ba7dac15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:22.782925Z",
     "start_time": "2024-11-17T20:42:22.001630Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, commit in enumerate(repo.iter_commits()):\n",
    "    matches = commit_pattern.findall(commit.message)\n",
    "    if matches:\n",
    "        all_commits[i // chunk_size][commit.hexsha] = matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4c1a373e89f5b",
   "metadata": {},
   "source": [
    "##### Extract commits using multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130373effbc78d63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.340191Z",
     "start_time": "2024-11-17T20:42:22.807689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20493 couples found.\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(process_commits, chunk) for chunk in all_commits]\n",
    "    for future in as_completed(futures):\n",
    "        couples = future.result()\n",
    "        all_couples.extend(couples)\n",
    "\n",
    "print(f\"{len(all_couples)} couples found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2357af0aba8ea1",
   "metadata": {},
   "source": [
    "### 2.3 - Filter data\n",
    "#### 2.3.1 - Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c794fd07dcf6972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.394541Z",
     "start_time": "2024-11-17T20:42:34.389006Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_dataframe : pd.DataFrame = pd.DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97a16882c9c061",
   "metadata": {},
   "source": [
    "#### 2.3.2 - Keep specific languages only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c87cfabddcab5dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.419899Z",
     "start_time": "2024-11-17T20:42:34.412498Z"
    }
   },
   "outputs": [],
   "source": [
    "section         : str   = \"GENERAL\"\n",
    "required_keys   : [str] = [\"Languages\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "# Languages without whitespaces\n",
    "languages                   : [str]         = config[section][\"Languages\"].split(\",\")\n",
    "languages                   : [str]         = [lang.strip() for lang in languages]\n",
    "commit_dataframe_filtered   : pd.DataFrame  = commit_dataframe[\n",
    "                                                commit_dataframe['File'].str.endswith(tuple(languages))\n",
    "                                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2bc65ad2e9d73",
   "metadata": {},
   "source": [
    "### 2.4 - Extract filter versions from git\n",
    "#### 2.4.1 - Extract versions "
   ]
  },
  {
   "cell_type": "code",
   "id": "14b04c2b987e7060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:58:07.984793Z",
     "start_time": "2024-11-17T23:58:07.819618Z"
    }
   },
   "source": [
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\",\n",
    "    \"HiveGitUrl\",\n",
    "    \"ReleasesRegex\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory  : str           = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "hive_git_repo_name  : str           = config[\"GIT\"][\"HiveGitRepoName\"]\n",
    "hive_git_url        : str           = config[\"GIT\"][\"HiveGitUrl\"]\n",
    "releases_regex      : [str]         = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "\n",
    "releases_regex      : [str]         = [regex.strip() for regex in releases_regex]\n",
    "release_regex       : [re.Pattern]  = [re.compile(regex) for regex in releases_regex]\n",
    "\n",
    "repo                : git.Repo      = git.Repo(hive_git_repo_dir)\n",
    "tags                                = repo.tags\n",
    "versions            : dict          = {}\n",
    "\n",
    "for tag in tags:\n",
    "    # Get the commit of the tag\n",
    "    commit = tag.commit\n",
    "    versions[tag.name] = commit"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "8495e8f36ec6e4be",
   "metadata": {},
   "source": [
    "#### 2.4.2 - Filter versions"
   ]
  },
  {
   "cell_type": "code",
   "id": "795bacdf5f22e7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:58:10.016841Z",
     "start_time": "2024-11-17T23:58:10.013107Z"
    }
   },
   "source": [
    "filtered_versions : dict = {}\n",
    "for version in versions:\n",
    "    for regex in release_regex:\n",
    "        if regex.match(version):\n",
    "            version_numbers = version.split(\"-\")[1]\n",
    "            filtered_versions[version_numbers] = versions[version]"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "9bdb5a076bcf1613",
   "metadata": {},
   "source": [
    "#### 2.4.3 - Dict : Sort version by date in descending order "
   ]
  },
  {
   "cell_type": "code",
   "id": "8e76cb5febbdcf71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:58:19.744335Z",
     "start_time": "2024-11-17T23:58:19.740306Z"
    }
   },
   "source": [
    "sorted_filtered_versions_date = dict(sorted(filtered_versions.items(), \n",
    "                                        key=lambda item: item[1].committed_datetime, \n",
    "                                        reverse=True))"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T23:58:27.325225Z",
     "start_time": "2024-11-17T23:58:27.318058Z"
    }
   },
   "cell_type": "code",
   "source": "len(sorted_filtered_versions_date)",
   "id": "83d94cb21858a1da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "43a6780352270941",
   "metadata": {},
   "source": [
    "## Part 3. - Understand analysis\n",
    "\n",
    "### 3.1 - Set up the configuration and understand project\n",
    "\n",
    "#### 3.1.1 - Check configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "980fde46eb35382a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.740849Z",
     "start_time": "2024-11-17T20:42:34.733704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hive\\\\hive.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section         : str   = \"UNDERSTAND\"    \n",
    "required_keys   : [str] = [\n",
    "    \"UnderstandCommand\",\n",
    "    \"UnderstandProjectName\",\n",
    "    \"UnderstandMetricsFileName\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "section         : str   = \"GIT\"\n",
    "required_keys   : [str] = [\n",
    "    \"HiveGitDirectory\",\n",
    "    \"HiveGitRepoName\"]\n",
    "\n",
    "testConfig(section, required_keys)\n",
    "\n",
    "hive_git_directory              : str   = config['GIT'][\"HiveGitDirectory\"]\n",
    "hive_repo_name                  : str   = config['GIT'][\"HiveGitRepoName\"]\n",
    "understand_project_name         : str   = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "und                             : str   = config[\"UNDERSTAND\"][\"UnderstandCommand\"]\n",
    "understand_metrics_file_name    : str   = config[\"UNDERSTAND\"][\"UnderstandMetricsFileName\"]\n",
    "\n",
    "und_project_path                : str   = os.path.join(hive_git_directory, understand_project_name)\n",
    "und_metrics_path                : str   = os.path.join(hive_git_directory, understand_project_name[:-4:] + \".csv\")\n",
    "hive_git_repo_dir               : str   = os.path.join(hive_git_directory, hive_repo_name)\n",
    "\n",
    "repo                            : git.Repo = git.Repo(hive_git_repo_dir)\n",
    "und_metrics_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd941f8b40611a5",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.2 - Understand commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617884aeeeab318e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.760245Z",
     "start_time": "2024-11-17T20:42:34.755724Z"
    }
   },
   "outputs": [],
   "source": [
    "und_create              : str = f\"{und} create -db {und_project_path} -languages Java c++\"\n",
    "und_purge               : str = f\"{und} purge -db {und_project_path}\"\n",
    "und_add                 : str = f\"{und} add {hive_git_repo_dir} -db {und_project_path}\"\n",
    "und_settings_metrics    : str = f\"{und} settings -metrics all -db {und_project_path}\"\n",
    "und_settings_output     : str = f\"{und} settings -metricsOutputFile  -db {und_metrics_path} {und_project_path}\"\n",
    "und_analyze             : str = f\"{und} analyze -db {und_project_path} -quiet\"\n",
    "und_analyze_changes     : str = f\"{und} analyze -db {und_project_path} -quiet -rescan -changed\"\n",
    "und_metrics             : str = f\"{und} metrics {und_project_path}\"\n",
    "\n",
    "def run_command(command : str):\n",
    "    command_args : [str] = command.split(\" \")\n",
    "    print(f\"Running command : \\n     {command}\")\n",
    "    process = Popen(command_args, stdout=PIPE, stderr=PIPE).communicate()[0]\n",
    "    print(process.decode(\"utf-8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83944d484fed7a5",
   "metadata": {},
   "source": [
    "#### 3.1.3 Create the Understand project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d72013eb5881a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.783806Z",
     "start_time": "2024-11-17T20:42:34.778245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if hive directory exists\n",
    "if not os.path.exists(hive_git_directory):\n",
    "    raise ValueError(f\"The directory {hive_git_directory} does not exist\")\n",
    "\n",
    "# Check if the Understand project exists\n",
    "if not os.path.exists(und_project_path):\n",
    "    run_command(und_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b624c2fd51c1c6d",
   "metadata": {},
   "source": [
    "#### 3.1.4 - Purge the Understand project\n",
    "**WARNING** : This will delete all the data in the Understand project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ca1af64a068c9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:42:34.937409Z",
     "start_time": "2024-11-17T20:42:34.799317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command : \n",
      "     und purge -db hive\\hive.und\n",
      "Database purged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_command(und_purge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2cc1812b35f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T20:47:15.329697Z",
     "start_time": "2024-11-17T20:42:34.953792Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out commit :  3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Adding commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264 to the Understand project\n",
      "Running command : \n",
      "     und add hive\\hiveRepo -db hive\\hive.und\n",
      "Directory: C:/Users/moshi/Documents/projects/Informatique/ETS/MGL869/MGL869-Lab-Hive/hive/hiveRepo already exists in project. Setting new properties. \n",
      "Files added: 8076\n",
      "\n",
      "Analyzing commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Running command : \n",
      "     und analyze -db hive\\hive.und -quiet -rescan -changed\n",
      "\n",
      "Exporting metrics for commit 3af4517eb8cfd9407ad34ed78a0b48b57dfaa264\n",
      "Running command : \n",
      "     und metrics hive\\hive.und\n"
     ]
    }
   ],
   "source": [
    "for version in sorted_filtered_versions_date :\n",
    "    t = time()\n",
    "    commit = sorted_filtered_versions_date[version]\n",
    "    print(\"Checking out commit : \", commit)\n",
    "    repo.git.checkout(commit)\n",
    "    print(f\"Adding commit {commit} to the Understand project\")\n",
    "    run_command(und_add)\n",
    "    print(f\"Analyzing commit {commit}\")\n",
    "    run_command(und_analyze_changes)\n",
    "    print(f\"Exporting metrics for commit {commit}\")\n",
    "    run_command(und_metrics)\n",
    "    # Copy UnderstandProjectName.csv to the output directory and set file name as UnderstandMetricsFileName\n",
    "    shutil.copy(und_metrics_path, os.path.join(config[\"OUTPUT\"][\"OutputDir\"], understand_metrics_file_name + str(version)))\n",
    "    print(t-time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
